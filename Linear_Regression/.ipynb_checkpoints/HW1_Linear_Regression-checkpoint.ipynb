{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California housing dataset.\n",
      "\n",
      "The original database is available from StatLib\n",
      "\n",
      "    http://lib.stat.cmu.edu/\n",
      "\n",
      "The data contains 20,640 observations on 9 variables.\n",
      "\n",
      "This dataset contains the average house value as target variable\n",
      "and the following input variables (features): average income,\n",
      "housing average age, average rooms, average bedrooms, population,\n",
      "average occupation, latitude, and longitude in that order.\n",
      "\n",
      "References\n",
      "----------\n",
      "\n",
      "Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "Statistics and Probability Letters, 33 (1997) 291-297.\n",
      "\n",
      "\n",
      "Features\n",
      "----------\n",
      "MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude\n",
      "\n",
      "Shape of dataset: (20640, 8)\n",
      "Shape of label: (20640,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "###### Do not modify here ###### \n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = graph_def\n",
    "    #strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "###### Do not modify  here ######\n",
    "\n",
    "###### Implement Data Preprocess here ######\n",
    "housing = fetch_california_housing()\n",
    "# Show description/ statisics about the dataset\n",
    "print(housing.DESCR)\n",
    "print('Features')\n",
    "print('----------')\n",
    "print(', '.join(housing.feature_names))\n",
    "print(\"\\nShape of dataset:\", housing.data.shape)\n",
    "print(\"Shape of label:\", housing.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of training set: (18576, 8)\n",
      "Shape of testing set: (2064, 8)\n",
      "Shape of training label: (18576,)\n",
      "Shape of testing label: (2064,)\n"
     ]
    }
   ],
   "source": [
    "cut = int(housing.data.shape[0]*0.9)\n",
    "x_train, x_test = housing.data[:cut], housing.data[cut:]\n",
    "y_train, y_test = housing.target[:cut], housing.target[cut:]\n",
    "\n",
    "print(\"\\nShape of training set:\", x_train.shape)\n",
    "print(\"Shape of testing set:\", x_test.shape)\n",
    "print(\"Shape of training label:\", y_train.shape)\n",
    "print(\"Shape of testing label:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'list'> to Tensor. Contents: [None, 1]. Consider casting elements to a supported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/chatbot/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/chatbot/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/chatbot/lib/python3.5/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 65\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got None",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-4a67e3f4b533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define variables to take input feature x, label y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# y = tf.placeholder(tf.float32, shape = [None, 1], name=\"Input\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/chatbot/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   2617\u001b[0m   \"\"\"\n\u001b[1;32m   2618\u001b[0m   result = _op_def_lib.apply_op(\"Reshape\", tensor=tensor, shape=shape,\n\u001b[0;32m-> 2619\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   2620\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/chatbot/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    491\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m               raise TypeError(\n",
      "\u001b[0;32m~/Documents/chatbot/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    491\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/chatbot/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/chatbot/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                          as_ref=False):\n\u001b[1;32m    120\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/chatbot/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 102\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/Documents/chatbot/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    462\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[1;32m    463\u001b[0m                       \u001b[0;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[1;32m    465\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed to convert object of type <class 'list'> to Tensor. Contents: [None, 1]. Consider casting elements to a supported type."
     ]
    }
   ],
   "source": [
    "# Clear graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Define variables to take input feature x, label y\n",
    "x = tf.placeholder(tf.float32, shape = [None, x_train.shape[1]], name=\"Input\")\n",
    "y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "# y = tf.placeholder(tf.float32, shape = [None, 1], name=\"Input\")\n",
    "\n",
    "# Define the weights for each element of input x, and random assign value as normal distribution\n",
    "W = tf.Variable(tf.random_normal(shape = [x_train.shape[1], 1]), name=\"weights\")\n",
    "# W = tf.Variable(tf.zeros([8,1]), dtype=tf.float32)\n",
    "\n",
    "# Define the bias for the linear function\n",
    "b = tf.Variable([0.0], dtype=tf.float32, name=\"Bias\")\n",
    "\n",
    "# Connect each elements for model\n",
    "linear_regression = tf.reshape(tf.matmul(x, W), [-1]) + b\n",
    "# linear_regression = tf.matmul(x, W) + b\n",
    "\n",
    "# Define cost/loss function\n",
    "error_rate = tf.abs((y - linear_regression)/y , name=\"Absolute_value\")\n",
    "# error_rate = (y - linear_regression)/y \n",
    "loss = tf.reduce_sum(error_rate, name=\"Sum_Error\")\n",
    "\n",
    "# Define training optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# Initialize Weights\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.14254451207834662&quot;).pbtxt = 'node {\\n  name: &quot;Input&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 8\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 8\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 8\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable&quot;\\n  input: &quot;zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bias/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Bias&quot;\\n  input: &quot;Bias/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Input&quot;\\n  input: &quot;Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MatMul&quot;\\n  input: &quot;Bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Y&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;sub&quot;\\n  input: &quot;Y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Absolute_value&quot;\\n  op: &quot;Abs&quot;\\n  input: &quot;truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank&quot;\\n  op: &quot;Rank&quot;\\n  input: &quot;Absolute_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;range/start&quot;\\n  input: &quot;Rank&quot;\\n  input: &quot;range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sum_Error&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Absolute_value&quot;\\n  input: &quot;range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Sum_Error&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Absolute_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;gradients/Sum_Error_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;range&quot;\\n  input: &quot;gradients/Sum_Error_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/Sum_Error_grad/add&quot;\\n  input: &quot;gradients/Sum_Error_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Sum_Error_grad/mod&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;gradients/Sum_Error_grad/range/start&quot;\\n  input: &quot;gradients/Sum_Error_grad/Size&quot;\\n  input: &quot;gradients/Sum_Error_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Sum_Error_grad/Shape_1&quot;\\n  input: &quot;gradients/Sum_Error_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;gradients/Sum_Error_grad/range&quot;\\n  input: &quot;gradients/Sum_Error_grad/mod&quot;\\n  input: &quot;gradients/Sum_Error_grad/Shape&quot;\\n  input: &quot;gradients/Sum_Error_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Sum_Error_grad/DynamicStitch&quot;\\n  input: &quot;gradients/Sum_Error_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/Sum_Error_grad/Shape&quot;\\n  input: &quot;gradients/Sum_Error_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/Sum_Error_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_Error_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Sum_Error_grad/Reshape&quot;\\n  input: &quot;gradients/Sum_Error_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Absolute_value_grad/Sign&quot;\\n  op: &quot;Sign&quot;\\n  input: &quot;truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Absolute_value_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Sum_Error_grad/Tile&quot;\\n  input: &quot;gradients/Absolute_value_grad/Sign&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/truediv_grad/Shape&quot;\\n  input: &quot;gradients/truediv_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/RealDiv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/Absolute_value_grad/mul&quot;\\n  input: &quot;Y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/truediv_grad/RealDiv&quot;\\n  input: &quot;gradients/truediv_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/truediv_grad/Sum&quot;\\n  input: &quot;gradients/truediv_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/RealDiv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/truediv_grad/Neg&quot;\\n  input: &quot;Y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/RealDiv_2&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/truediv_grad/RealDiv_1&quot;\\n  input: &quot;Y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Absolute_value_grad/mul&quot;\\n  input: &quot;gradients/truediv_grad/RealDiv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/truediv_grad/mul&quot;\\n  input: &quot;gradients/truediv_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/truediv_grad/Sum_1&quot;\\n  input: &quot;gradients/truediv_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/truediv_grad/Reshape&quot;\\n  input: &quot;^gradients/truediv_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/truediv_grad/Reshape&quot;\\n  input: &quot;^gradients/truediv_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/truediv_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/truediv_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/truediv_grad/Reshape_1&quot;\\n  input: &quot;^gradients/truediv_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/truediv_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/truediv_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Sum&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/truediv_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Neg&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum_1&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  input: &quot;Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Input&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_Variable/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;Variable&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_Bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;Bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_Variable/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_Bias/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Variable/Assign&quot;\\n  input: &quot;^Bias/Assign&quot;\\n}\\nversions {\\n  producer: 24\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.14254451207834662&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Start TF session ######\n",
    "with tf.Session() as sess:\n",
    "    show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directly Train\n",
    "Let's try directly train model without data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = y_train.reshape((y_train.shape[0], 1))\n",
    "y_test_ = y_test.reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Round  1\n",
      "Training - loss: 154735802\n",
      "Testing  - loss: 183434041\n",
      "\n",
      "Round  101\n",
      "Training - loss: 154735787\n",
      "Testing  - loss: 183434041\n",
      "\n",
      "Round  201\n",
      "Training - loss: 154735802\n",
      "Testing  - loss: 183434041\n",
      "\n",
      "Round  301\n",
      "Training - loss: 154735802\n",
      "Testing  - loss: 183434041\n",
      "\n",
      "Round  401\n",
      "Training - loss: 154735802\n",
      "Testing  - loss: 183434041\n",
      "\n",
      "Round  501\n",
      "Training - loss: 154735802\n",
      "Testing  - loss: 183434041\n",
      "\n",
      "Round  601\n",
      "Training - loss: 154735802\n",
      "Testing  - loss: 183434041\n",
      "\n",
      "Round  701\n",
      "Training - loss: 154735787\n",
      "Testing  - loss: 183434041\n",
      "\n",
      "Round  801\n",
      "Training - loss: 154735787\n",
      "Testing  - loss: 183434041\n",
      "\n",
      "Round  901\n",
      "Training - loss: 154735802\n",
      "Testing  - loss: 183434041\n",
      "Final Training - loss: 0650\n",
      "Final Testing  - loss: 0773\n"
     ]
    }
   ],
   "source": [
    "###### Start TF session ######\n",
    "with tf.Session() as sess:\n",
    "    # training loop\n",
    "    sess.run(init) # reset values to wrong\n",
    "    for i in range(1000):\n",
    "        sess.run(train, {x: x_train, y: y_train_})\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\nRound \",i+1)\n",
    "            l = sess.run(loss, {x: x_train, y: y_train_})\n",
    "            print(\"Training - loss: %.4d\"%(l/ y_train_.shape[0]))\n",
    "            l = sess.run(loss, {x: x_test, y: y_test_})\n",
    "            print(\"Testing  - loss: %.4d\"%(l/ y_test_.shape[0]))\n",
    "            \n",
    "    # evaluate training accuracy\n",
    "    y_, e_, l = sess.run([y, error_rate, loss], {x: x_train, y: y_train_})\n",
    "    print(\"Final Training - loss: %.4d\"%(l/ y_train_.shape[0]))\n",
    "    lr_1, e_1, l1 = sess.run([linear_regression, error_rate, loss], {x: x_test, y: y_test_})\n",
    "    print(\"Final Testing  - loss: %.4d\"%(l1/ y_test_.shape[0]))\n",
    "    \n",
    "#     show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.214,  1.904,  1.843, ...,  0.923,  0.847,  0.894])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 494130.96875,  558902.5625 ,  658362.6875 , ...,  390438.21875,\n",
       "        305750.125  ,  511571.375  ], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 407026.15625,  293540.28125,  357222.375  , ...,  423008.96875,\n",
       "        360979.09375,  572226.5    ], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.31296e+08"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train after pre-processing\n",
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18576.000000</td>\n",
       "      <td>18576.000000</td>\n",
       "      <td>18576.000000</td>\n",
       "      <td>18576.000000</td>\n",
       "      <td>18576.000000</td>\n",
       "      <td>18576.000000</td>\n",
       "      <td>18576.000000</td>\n",
       "      <td>18576.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.917221</td>\n",
       "      <td>29.118594</td>\n",
       "      <td>5.403187</td>\n",
       "      <td>1.095654</td>\n",
       "      <td>1433.185831</td>\n",
       "      <td>3.020782</td>\n",
       "      <td>35.430371</td>\n",
       "      <td>-119.409006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.932617</td>\n",
       "      <td>12.658810</td>\n",
       "      <td>2.543630</td>\n",
       "      <td>0.485395</td>\n",
       "      <td>1142.294876</td>\n",
       "      <td>6.078652</td>\n",
       "      <td>2.061388</td>\n",
       "      <td>1.993468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.585725</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.391440</td>\n",
       "      <td>1.005917</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>2.421582</td>\n",
       "      <td>33.900000</td>\n",
       "      <td>-121.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.571900</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.188982</td>\n",
       "      <td>1.048474</td>\n",
       "      <td>1170.000000</td>\n",
       "      <td>2.819232</td>\n",
       "      <td>34.160000</td>\n",
       "      <td>-118.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.803600</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>6.031433</td>\n",
       "      <td>1.098765</td>\n",
       "      <td>1727.000000</td>\n",
       "      <td>3.296951</td>\n",
       "      <td>37.580000</td>\n",
       "      <td>-117.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>599.714286</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  18576.000000  18576.000000  18576.000000  18576.000000  18576.000000   \n",
       "mean       3.917221     29.118594      5.403187      1.095654   1433.185831   \n",
       "std        1.932617     12.658810      2.543630      0.485395   1142.294876   \n",
       "min        0.499900      1.000000      0.846154      0.375000      3.000000   \n",
       "25%        2.585725     19.000000      4.391440      1.005917    793.000000   \n",
       "50%        3.571900     30.000000      5.188982      1.048474   1170.000000   \n",
       "75%        4.803600     38.000000      6.031433      1.098765   1727.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude  \n",
       "count  18576.000000  18576.000000  18576.000000  \n",
       "mean       3.020782     35.430371   -119.409006  \n",
       "std        6.078652      2.061388      1.993468  \n",
       "min        0.692308     32.540000   -124.350000  \n",
       "25%        2.421582     33.900000   -121.540000  \n",
       "50%        2.819232     34.160000   -118.370000  \n",
       "75%        3.296951     37.580000   -117.950000  \n",
       "max      599.714286     41.950000   -114.310000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pd = pd.DataFrame(x_train, columns=housing.feature_names)\n",
    "x_train_pd.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.280834</td>\n",
       "      <td>0.938588</td>\n",
       "      <td>0.621529</td>\n",
       "      <td>-0.148012</td>\n",
       "      <td>-0.972766</td>\n",
       "      <td>-0.076534</td>\n",
       "      <td>1.188340</td>\n",
       "      <td>-1.415119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.268519</td>\n",
       "      <td>-0.641339</td>\n",
       "      <td>0.328251</td>\n",
       "      <td>-0.254995</td>\n",
       "      <td>0.847254</td>\n",
       "      <td>-0.149859</td>\n",
       "      <td>1.178637</td>\n",
       "      <td>-1.410103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.728319</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>1.134185</td>\n",
       "      <td>-0.045751</td>\n",
       "      <td>-0.820441</td>\n",
       "      <td>-0.035949</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.420135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.893027</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>0.162824</td>\n",
       "      <td>-0.046549</td>\n",
       "      <td>-0.766165</td>\n",
       "      <td>-0.077786</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.425152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.036749</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>0.345438</td>\n",
       "      <td>-0.030022</td>\n",
       "      <td>-0.760037</td>\n",
       "      <td>-0.138076</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.425152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.061874</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.252210</td>\n",
       "      <td>0.016426</td>\n",
       "      <td>-0.893102</td>\n",
       "      <td>-0.144915</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.425152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.133560</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.185279</td>\n",
       "      <td>-0.297267</td>\n",
       "      <td>-0.296934</td>\n",
       "      <td>-0.146805</td>\n",
       "      <td>1.168935</td>\n",
       "      <td>-1.425152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.412508</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.238109</td>\n",
       "      <td>-0.069696</td>\n",
       "      <td>-0.241782</td>\n",
       "      <td>-0.202763</td>\n",
       "      <td>1.168935</td>\n",
       "      <td>-1.425152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.950432</td>\n",
       "      <td>1.017584</td>\n",
       "      <td>-0.436018</td>\n",
       "      <td>0.045310</td>\n",
       "      <td>-0.198885</td>\n",
       "      <td>-0.163505</td>\n",
       "      <td>1.168935</td>\n",
       "      <td>-1.430168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.116951</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.170071</td>\n",
       "      <td>-0.217261</td>\n",
       "      <td>0.103138</td>\n",
       "      <td>-0.139589</td>\n",
       "      <td>1.168935</td>\n",
       "      <td>-1.425152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.369510</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>0.029259</td>\n",
       "      <td>-0.033070</td>\n",
       "      <td>-0.458013</td>\n",
       "      <td>-0.124551</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.430168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.334635</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.247956</td>\n",
       "      <td>-0.146542</td>\n",
       "      <td>0.061993</td>\n",
       "      <td>-0.159860</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.430168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.435793</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.031663</td>\n",
       "      <td>-0.170651</td>\n",
       "      <td>-0.293432</td>\n",
       "      <td>-0.110983</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.430168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.643490</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.551647</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>-0.952631</td>\n",
       "      <td>-0.170765</td>\n",
       "      <td>1.168935</td>\n",
       "      <td>-1.430168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.035135</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.448290</td>\n",
       "      <td>-0.177126</td>\n",
       "      <td>-0.193633</td>\n",
       "      <td>-0.175358</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.430168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.927354</td>\n",
       "      <td>1.649555</td>\n",
       "      <td>-0.456341</td>\n",
       "      <td>-0.048793</td>\n",
       "      <td>-0.644480</td>\n",
       "      <td>-0.062618</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.430168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.591023</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>0.210876</td>\n",
       "      <td>-0.097478</td>\n",
       "      <td>-0.560438</td>\n",
       "      <td>-0.102821</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.435185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.929838</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.530888</td>\n",
       "      <td>-0.265056</td>\n",
       "      <td>-0.687376</td>\n",
       "      <td>-0.145126</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.435185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.996638</td>\n",
       "      <td>1.649555</td>\n",
       "      <td>-0.023396</td>\n",
       "      <td>-0.020056</td>\n",
       "      <td>-0.387978</td>\n",
       "      <td>-0.108250</td>\n",
       "      <td>1.168935</td>\n",
       "      <td>-1.430168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.679866</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>0.024480</td>\n",
       "      <td>-0.024758</td>\n",
       "      <td>-0.650608</td>\n",
       "      <td>-0.084178</td>\n",
       "      <td>1.168935</td>\n",
       "      <td>-1.435185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.324329</td>\n",
       "      <td>0.859592</td>\n",
       "      <td>-0.345605</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>-0.896604</td>\n",
       "      <td>-0.091620</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.435185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.140278</td>\n",
       "      <td>1.017584</td>\n",
       "      <td>-0.363671</td>\n",
       "      <td>-0.191435</td>\n",
       "      <td>-0.441380</td>\n",
       "      <td>-0.079381</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.435185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.134327</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.120675</td>\n",
       "      <td>0.074466</td>\n",
       "      <td>-0.366093</td>\n",
       "      <td>-0.147623</td>\n",
       "      <td>1.168935</td>\n",
       "      <td>-1.435185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.898585</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>-0.120996</td>\n",
       "      <td>-0.507912</td>\n",
       "      <td>-0.065173</td>\n",
       "      <td>1.168935</td>\n",
       "      <td>-1.435185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.681574</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.052305</td>\n",
       "      <td>-0.123835</td>\n",
       "      <td>-0.373972</td>\n",
       "      <td>-0.104776</td>\n",
       "      <td>1.168935</td>\n",
       "      <td>-1.435185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.783094</td>\n",
       "      <td>0.938588</td>\n",
       "      <td>-0.356730</td>\n",
       "      <td>-0.127814</td>\n",
       "      <td>-0.977143</td>\n",
       "      <td>-0.058716</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.440201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.754169</td>\n",
       "      <td>1.570559</td>\n",
       "      <td>-0.265429</td>\n",
       "      <td>-0.153964</td>\n",
       "      <td>-0.723268</td>\n",
       "      <td>-0.079135</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.440201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.091380</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.244662</td>\n",
       "      <td>-0.072519</td>\n",
       "      <td>-0.289930</td>\n",
       "      <td>-0.040299</td>\n",
       "      <td>1.173786</td>\n",
       "      <td>-1.440201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.177067</td>\n",
       "      <td>1.649555</td>\n",
       "      <td>-0.393727</td>\n",
       "      <td>-0.114308</td>\n",
       "      <td>-0.264543</td>\n",
       "      <td>-0.103586</td>\n",
       "      <td>1.168935</td>\n",
       "      <td>-1.440201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.153731</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.275182</td>\n",
       "      <td>-0.130606</td>\n",
       "      <td>-0.908860</td>\n",
       "      <td>-0.077714</td>\n",
       "      <td>1.168935</td>\n",
       "      <td>-1.440201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18546</th>\n",
       "      <td>-0.729850</td>\n",
       "      <td>-0.878329</td>\n",
       "      <td>-0.519885</td>\n",
       "      <td>0.208062</td>\n",
       "      <td>-0.036931</td>\n",
       "      <td>-0.148118</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>-1.314791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18547</th>\n",
       "      <td>-1.429161</td>\n",
       "      <td>1.175577</td>\n",
       "      <td>-0.444171</td>\n",
       "      <td>0.247579</td>\n",
       "      <td>-0.970140</td>\n",
       "      <td>-0.112303</td>\n",
       "      <td>0.746889</td>\n",
       "      <td>-1.309775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18548</th>\n",
       "      <td>-1.165787</td>\n",
       "      <td>0.780595</td>\n",
       "      <td>-0.746271</td>\n",
       "      <td>-0.010084</td>\n",
       "      <td>-0.059692</td>\n",
       "      <td>-0.126394</td>\n",
       "      <td>0.746889</td>\n",
       "      <td>-1.309775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18549</th>\n",
       "      <td>-0.983133</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-1.125244</td>\n",
       "      <td>-0.197064</td>\n",
       "      <td>-0.331951</td>\n",
       "      <td>0.071555</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>-1.309775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18550</th>\n",
       "      <td>-0.167349</td>\n",
       "      <td>0.859592</td>\n",
       "      <td>-0.472454</td>\n",
       "      <td>-0.389742</td>\n",
       "      <td>-0.978019</td>\n",
       "      <td>-0.122955</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>-1.314791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18551</th>\n",
       "      <td>-0.772124</td>\n",
       "      <td>-0.088365</td>\n",
       "      <td>-0.483231</td>\n",
       "      <td>-0.004424</td>\n",
       "      <td>-0.444006</td>\n",
       "      <td>-0.101270</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>-1.314791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18552</th>\n",
       "      <td>0.144456</td>\n",
       "      <td>0.227621</td>\n",
       "      <td>-0.194736</td>\n",
       "      <td>-0.105657</td>\n",
       "      <td>-0.552559</td>\n",
       "      <td>-0.046652</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>-1.319808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18553</th>\n",
       "      <td>-0.905777</td>\n",
       "      <td>1.017584</td>\n",
       "      <td>-0.090465</td>\n",
       "      <td>-0.137636</td>\n",
       "      <td>-1.079569</td>\n",
       "      <td>-0.180584</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>-1.319808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18554</th>\n",
       "      <td>-0.688559</td>\n",
       "      <td>1.017584</td>\n",
       "      <td>-0.177149</td>\n",
       "      <td>0.087099</td>\n",
       "      <td>-0.639227</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>-1.319808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18555</th>\n",
       "      <td>-0.205535</td>\n",
       "      <td>0.227621</td>\n",
       "      <td>0.194254</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>-0.272422</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>-1.314791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18556</th>\n",
       "      <td>0.279144</td>\n",
       "      <td>0.543606</td>\n",
       "      <td>-0.113146</td>\n",
       "      <td>-0.197064</td>\n",
       "      <td>-0.309190</td>\n",
       "      <td>-0.008842</td>\n",
       "      <td>0.737187</td>\n",
       "      <td>-1.319808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18557</th>\n",
       "      <td>-0.406713</td>\n",
       "      <td>-0.799332</td>\n",
       "      <td>-0.497503</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>-0.971015</td>\n",
       "      <td>-0.177780</td>\n",
       "      <td>0.717783</td>\n",
       "      <td>-1.304759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18558</th>\n",
       "      <td>0.148648</td>\n",
       "      <td>0.069628</td>\n",
       "      <td>0.082374</td>\n",
       "      <td>-0.054161</td>\n",
       "      <td>-0.690878</td>\n",
       "      <td>0.115447</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>-1.324824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18559</th>\n",
       "      <td>0.301549</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>0.431200</td>\n",
       "      <td>1.245060</td>\n",
       "      <td>-1.233645</td>\n",
       "      <td>-0.102125</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>-1.329840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18560</th>\n",
       "      <td>-0.046735</td>\n",
       "      <td>-0.878329</td>\n",
       "      <td>-0.208295</td>\n",
       "      <td>-0.278031</td>\n",
       "      <td>-0.299560</td>\n",
       "      <td>-0.105070</td>\n",
       "      <td>0.698378</td>\n",
       "      <td>-1.324824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18561</th>\n",
       "      <td>0.025602</td>\n",
       "      <td>-0.167361</td>\n",
       "      <td>0.153252</td>\n",
       "      <td>-0.010867</td>\n",
       "      <td>-0.413366</td>\n",
       "      <td>-0.036033</td>\n",
       "      <td>0.737187</td>\n",
       "      <td>-1.319808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18562</th>\n",
       "      <td>-0.489502</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>1.848507</td>\n",
       "      <td>1.727005</td>\n",
       "      <td>-0.557812</td>\n",
       "      <td>-0.103706</td>\n",
       "      <td>0.761443</td>\n",
       "      <td>-1.319808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18563</th>\n",
       "      <td>-0.575189</td>\n",
       "      <td>0.227621</td>\n",
       "      <td>-0.743492</td>\n",
       "      <td>-0.167350</td>\n",
       "      <td>0.053239</td>\n",
       "      <td>0.093864</td>\n",
       "      <td>0.717783</td>\n",
       "      <td>-1.174333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18564</th>\n",
       "      <td>-0.419649</td>\n",
       "      <td>-0.009368</td>\n",
       "      <td>-0.308562</td>\n",
       "      <td>-0.047662</td>\n",
       "      <td>-0.499158</td>\n",
       "      <td>0.044930</td>\n",
       "      <td>0.722634</td>\n",
       "      <td>-1.169316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18565</th>\n",
       "      <td>-0.761206</td>\n",
       "      <td>-0.957325</td>\n",
       "      <td>-0.196366</td>\n",
       "      <td>-0.010122</td>\n",
       "      <td>-0.210266</td>\n",
       "      <td>-0.133504</td>\n",
       "      <td>0.722634</td>\n",
       "      <td>-1.169316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18566</th>\n",
       "      <td>-0.655391</td>\n",
       "      <td>-1.194314</td>\n",
       "      <td>-0.231834</td>\n",
       "      <td>-0.202975</td>\n",
       "      <td>-0.072823</td>\n",
       "      <td>-0.178314</td>\n",
       "      <td>0.722634</td>\n",
       "      <td>-1.169316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18567</th>\n",
       "      <td>-0.405937</td>\n",
       "      <td>-0.404350</td>\n",
       "      <td>-0.290162</td>\n",
       "      <td>-0.154094</td>\n",
       "      <td>0.727320</td>\n",
       "      <td>-0.065372</td>\n",
       "      <td>0.727485</td>\n",
       "      <td>-1.174333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18568</th>\n",
       "      <td>-0.164141</td>\n",
       "      <td>1.491562</td>\n",
       "      <td>-0.162865</td>\n",
       "      <td>-0.242719</td>\n",
       "      <td>-0.317069</td>\n",
       "      <td>-0.008887</td>\n",
       "      <td>0.722634</td>\n",
       "      <td>-1.174333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18569</th>\n",
       "      <td>-0.753238</td>\n",
       "      <td>1.333570</td>\n",
       "      <td>-0.368612</td>\n",
       "      <td>-0.088989</td>\n",
       "      <td>-0.319695</td>\n",
       "      <td>0.079106</td>\n",
       "      <td>0.722634</td>\n",
       "      <td>-1.174333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18570</th>\n",
       "      <td>-0.359937</td>\n",
       "      <td>0.543606</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.118631</td>\n",
       "      <td>0.018221</td>\n",
       "      <td>0.110152</td>\n",
       "      <td>0.722634</td>\n",
       "      <td>-1.179349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18571</th>\n",
       "      <td>-0.261159</td>\n",
       "      <td>1.333570</td>\n",
       "      <td>-0.713966</td>\n",
       "      <td>-0.251690</td>\n",
       "      <td>-0.274172</td>\n",
       "      <td>0.200973</td>\n",
       "      <td>0.722634</td>\n",
       "      <td>-1.179349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>-1.153731</td>\n",
       "      <td>1.807548</td>\n",
       "      <td>-0.909685</td>\n",
       "      <td>0.091992</td>\n",
       "      <td>-0.289930</td>\n",
       "      <td>-0.034474</td>\n",
       "      <td>0.717783</td>\n",
       "      <td>-1.174333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18573</th>\n",
       "      <td>-1.012265</td>\n",
       "      <td>-0.483347</td>\n",
       "      <td>-0.790040</td>\n",
       "      <td>0.137167</td>\n",
       "      <td>-0.064945</td>\n",
       "      <td>0.097650</td>\n",
       "      <td>0.717783</td>\n",
       "      <td>-1.179349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18574</th>\n",
       "      <td>-0.702323</td>\n",
       "      <td>1.017584</td>\n",
       "      <td>-1.013017</td>\n",
       "      <td>-0.265169</td>\n",
       "      <td>0.769341</td>\n",
       "      <td>0.288893</td>\n",
       "      <td>0.717783</td>\n",
       "      <td>-1.174333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18575</th>\n",
       "      <td>-0.560080</td>\n",
       "      <td>-1.668292</td>\n",
       "      <td>-0.637612</td>\n",
       "      <td>-0.105245</td>\n",
       "      <td>1.003956</td>\n",
       "      <td>0.094187</td>\n",
       "      <td>0.717783</td>\n",
       "      <td>-1.184365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18576 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
       "0      2.280834  0.938588  0.621529  -0.148012   -0.972766 -0.076534   \n",
       "1      2.268519 -0.641339  0.328251  -0.254995    0.847254 -0.149859   \n",
       "2      1.728319  1.807548  1.134185  -0.045751   -0.820441 -0.035949   \n",
       "3      0.893027  1.807548  0.162824  -0.046549   -0.766165 -0.077786   \n",
       "4     -0.036749  1.807548  0.345438  -0.030022   -0.760037 -0.138076   \n",
       "5      0.061874  1.807548 -0.252210   0.016426   -0.893102 -0.144915   \n",
       "6     -0.133560  1.807548 -0.185279  -0.297267   -0.296934 -0.146805   \n",
       "7     -0.412508  1.807548 -0.238109  -0.069696   -0.241782 -0.202763   \n",
       "8     -0.950432  1.017584 -0.436018   0.045310   -0.198885 -0.163505   \n",
       "9     -0.116951  1.807548 -0.170071  -0.217261    0.103138 -0.139589   \n",
       "10    -0.369510  1.807548  0.029259  -0.033070   -0.458013 -0.124551   \n",
       "11    -0.334635  1.807548 -0.247956  -0.146542    0.061993 -0.159860   \n",
       "12    -0.435793  1.807548 -0.031663  -0.170651   -0.293432 -0.110983   \n",
       "13    -0.643490  1.807548 -0.551647   0.004218   -0.952631 -0.170765   \n",
       "14    -1.035135  1.807548 -0.448290  -0.177126   -0.193633 -0.175358   \n",
       "15    -0.927354  1.649555 -0.456341  -0.048793   -0.644480 -0.062618   \n",
       "16    -0.591023  1.807548  0.210876  -0.097478   -0.560438 -0.102821   \n",
       "17    -0.929838  1.807548 -0.530888  -0.265056   -0.687376 -0.145126   \n",
       "18    -0.996638  1.649555 -0.023396  -0.020056   -0.387978 -0.108250   \n",
       "19    -0.679866  1.807548  0.024480  -0.024758   -0.650608 -0.084178   \n",
       "20    -1.324329  0.859592 -0.345605   0.026329   -0.896604 -0.091620   \n",
       "21    -1.140278  1.017584 -0.363671  -0.191435   -0.441380 -0.079381   \n",
       "22    -1.134327  1.807548 -0.120675   0.074466   -0.366093 -0.147623   \n",
       "23    -0.898585  1.807548 -0.082300  -0.120996   -0.507912 -0.065173   \n",
       "24    -0.681574  1.807548 -0.052305  -0.123835   -0.373972 -0.104776   \n",
       "25    -0.783094  0.938588 -0.356730  -0.127814   -0.977143 -0.058716   \n",
       "26    -0.754169  1.570559 -0.265429  -0.153964   -0.723268 -0.079135   \n",
       "27    -1.091380  1.807548 -0.244662  -0.072519   -0.289930 -0.040299   \n",
       "28    -1.177067  1.649555 -0.393727  -0.114308   -0.264543 -0.103586   \n",
       "29    -1.153731  1.807548 -0.275182  -0.130606   -0.908860 -0.077714   \n",
       "...         ...       ...       ...        ...         ...       ...   \n",
       "18546 -0.729850 -0.878329 -0.519885   0.208062   -0.036931 -0.148118   \n",
       "18547 -1.429161  1.175577 -0.444171   0.247579   -0.970140 -0.112303   \n",
       "18548 -1.165787  0.780595 -0.746271  -0.010084   -0.059692 -0.126394   \n",
       "18549 -0.983133  1.807548 -1.125244  -0.197064   -0.331951  0.071555   \n",
       "18550 -0.167349  0.859592 -0.472454  -0.389742   -0.978019 -0.122955   \n",
       "18551 -0.772124 -0.088365 -0.483231  -0.004424   -0.444006 -0.101270   \n",
       "18552  0.144456  0.227621 -0.194736  -0.105657   -0.552559 -0.046652   \n",
       "18553 -0.905777  1.017584 -0.090465  -0.137636   -1.079569 -0.180584   \n",
       "18554 -0.688559  1.017584 -0.177149   0.087099   -0.639227  0.001545   \n",
       "18555 -0.205535  0.227621  0.194254   0.003386   -0.272422  0.001917   \n",
       "18556  0.279144  0.543606 -0.113146  -0.197064   -0.309190 -0.008842   \n",
       "18557 -0.406713 -0.799332 -0.497503   0.099010   -0.971015 -0.177780   \n",
       "18558  0.148648  0.069628  0.082374  -0.054161   -0.690878  0.115447   \n",
       "18559  0.301549  1.807548  0.431200   1.245060   -1.233645 -0.102125   \n",
       "18560 -0.046735 -0.878329 -0.208295  -0.278031   -0.299560 -0.105070   \n",
       "18561  0.025602 -0.167361  0.153252  -0.010867   -0.413366 -0.036033   \n",
       "18562 -0.489502  1.807548  1.848507   1.727005   -0.557812 -0.103706   \n",
       "18563 -0.575189  0.227621 -0.743492  -0.167350    0.053239  0.093864   \n",
       "18564 -0.419649 -0.009368 -0.308562  -0.047662   -0.499158  0.044930   \n",
       "18565 -0.761206 -0.957325 -0.196366  -0.010122   -0.210266 -0.133504   \n",
       "18566 -0.655391 -1.194314 -0.231834  -0.202975   -0.072823 -0.178314   \n",
       "18567 -0.405937 -0.404350 -0.290162  -0.154094    0.727320 -0.065372   \n",
       "18568 -0.164141  1.491562 -0.162865  -0.242719   -0.317069 -0.008887   \n",
       "18569 -0.753238  1.333570 -0.368612  -0.088989   -0.319695  0.079106   \n",
       "18570 -0.359937  0.543606 -0.032784  -0.118631    0.018221  0.110152   \n",
       "18571 -0.261159  1.333570 -0.713966  -0.251690   -0.274172  0.200973   \n",
       "18572 -1.153731  1.807548 -0.909685   0.091992   -0.289930 -0.034474   \n",
       "18573 -1.012265 -0.483347 -0.790040   0.137167   -0.064945  0.097650   \n",
       "18574 -0.702323  1.017584 -1.013017  -0.265169    0.769341  0.288893   \n",
       "18575 -0.560080 -1.668292 -0.637612  -0.105245    1.003956  0.094187   \n",
       "\n",
       "       Latitude  Longitude  \n",
       "0      1.188340  -1.415119  \n",
       "1      1.178637  -1.410103  \n",
       "2      1.173786  -1.420135  \n",
       "3      1.173786  -1.425152  \n",
       "4      1.173786  -1.425152  \n",
       "5      1.173786  -1.425152  \n",
       "6      1.168935  -1.425152  \n",
       "7      1.168935  -1.425152  \n",
       "8      1.168935  -1.430168  \n",
       "9      1.168935  -1.425152  \n",
       "10     1.173786  -1.430168  \n",
       "11     1.173786  -1.430168  \n",
       "12     1.173786  -1.430168  \n",
       "13     1.168935  -1.430168  \n",
       "14     1.173786  -1.430168  \n",
       "15     1.173786  -1.430168  \n",
       "16     1.173786  -1.435185  \n",
       "17     1.173786  -1.435185  \n",
       "18     1.168935  -1.430168  \n",
       "19     1.168935  -1.435185  \n",
       "20     1.173786  -1.435185  \n",
       "21     1.173786  -1.435185  \n",
       "22     1.168935  -1.435185  \n",
       "23     1.168935  -1.435185  \n",
       "24     1.168935  -1.435185  \n",
       "25     1.173786  -1.440201  \n",
       "26     1.173786  -1.440201  \n",
       "27     1.173786  -1.440201  \n",
       "28     1.168935  -1.440201  \n",
       "29     1.168935  -1.440201  \n",
       "...         ...        ...  \n",
       "18546  0.742038  -1.314791  \n",
       "18547  0.746889  -1.309775  \n",
       "18548  0.746889  -1.309775  \n",
       "18549  0.742038  -1.309775  \n",
       "18550  0.742038  -1.314791  \n",
       "18551  0.742038  -1.314791  \n",
       "18552  0.742038  -1.319808  \n",
       "18553  0.742038  -1.319808  \n",
       "18554  0.742038  -1.319808  \n",
       "18555  0.742038  -1.314791  \n",
       "18556  0.737187  -1.319808  \n",
       "18557  0.717783  -1.304759  \n",
       "18558  0.742038  -1.324824  \n",
       "18559  0.742038  -1.329840  \n",
       "18560  0.698378  -1.324824  \n",
       "18561  0.737187  -1.319808  \n",
       "18562  0.761443  -1.319808  \n",
       "18563  0.717783  -1.174333  \n",
       "18564  0.722634  -1.169316  \n",
       "18565  0.722634  -1.169316  \n",
       "18566  0.722634  -1.169316  \n",
       "18567  0.727485  -1.174333  \n",
       "18568  0.722634  -1.174333  \n",
       "18569  0.722634  -1.174333  \n",
       "18570  0.722634  -1.179349  \n",
       "18571  0.722634  -1.179349  \n",
       "18572  0.717783  -1.174333  \n",
       "18573  0.717783  -1.179349  \n",
       "18574  0.717783  -1.174333  \n",
       "18575  0.717783  -1.184365  \n",
       "\n",
       "[18576 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "x_train_standard_pd = x_train_pd.sub(x_train_pd.mean(),axis=1).div(x_train_pd.std(),axis=1)\n",
    "x_train_standard = x_train_standard_pd.values\n",
    "x_train_standard_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value change between standardization before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   8.3252       41.            6.98412698    1.02380952  322.\n",
      "    2.55555556   37.88       -122.23      ]\n",
      "[ 2.28083372  0.9385879   0.62152884 -0.14801185 -0.97276619 -0.07653445\n",
      "  1.18833965 -1.415119  ]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(x_train_standard[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing data\n",
    "x_test_pd = pd.DataFrame(x_test, columns=housing.feature_names)\n",
    "x_test_standard = x_test_pd.sub(x_train_pd.mean(),axis=1).div(x_train_pd.std(),axis=1).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Round  1\n",
      "Training - loss: 22460\n",
      "Testing  - loss: 27764\n",
      "\n",
      " Round  101\n",
      "Training - loss: 4132\n",
      "Testing  - loss: 4791\n",
      "\n",
      " Round  201\n",
      "Training - loss: 4121\n",
      "Testing  - loss: 4781\n",
      "\n",
      " Round  301\n",
      "Training - loss: 4180\n",
      "Testing  - loss: 4838\n",
      "\n",
      " Round  401\n",
      "Training - loss: 4132\n",
      "Testing  - loss: 4790\n",
      "\n",
      " Round  501\n",
      "Training - loss: 4173\n",
      "Testing  - loss: 4831\n",
      "\n",
      " Round  601\n",
      "Training - loss: 4161\n",
      "Testing  - loss: 4820\n",
      "\n",
      " Round  701\n",
      "Training - loss: 4165\n",
      "Testing  - loss: 4824\n",
      "\n",
      " Round  801\n",
      "Training - loss: 4193\n",
      "Testing  - loss: 4852\n",
      "\n",
      " Round  901\n",
      "Training - loss: 4216\n",
      "Testing  - loss: 4875\n",
      "Final Training - loss: 2659\n",
      "Final Testing  - loss: 3108\n"
     ]
    }
   ],
   "source": [
    "###### Start TF session ######\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # re-assign Weights\n",
    "    # training loop\n",
    "    for i in range(1000):\n",
    "        sess.run(train, {x: x_train_standard, y: y_train})\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\n Round \",i+1)\n",
    "            l = sess.run(loss, {x: x_train, y: y_train})\n",
    "            print(\"Training - loss: %.4d\"%(l/ y_train.shape[0]))\n",
    "            l = sess.run(loss, {x: x_test, y: y_test})\n",
    "            print(\"Testing  - loss: %.4d\"%(l/ y_test.shape[0]))\n",
    "\n",
    "    # evaluate training accuracy\n",
    "    l = sess.run(loss, {x: x_train, y: y_train})\n",
    "    print(\"Final Training - loss: %.4d\"%(l/ y_train.shape[0]))\n",
    "    lr_1, e_1, l1 = sess.run([linear_regression, error_rate, loss], {x: x_test, y: y_test})\n",
    "    print(\"Final Testing  - loss: %.4d\"%(l1/ y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.214,  1.904,  1.843, ...,  0.923,  0.847,  0.894])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  761.96386719,   879.55963135,  1044.70043945, ...,   583.88165283,\n",
       "         453.7093811 ,   790.68371582], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 626.64733887,  460.95358276,  565.84771729, ...,  631.59118652,\n",
       "        534.6663208 ,  883.43371582], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1319083.5"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
