{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California housing dataset.\n",
      "\n",
      "The original database is available from StatLib\n",
      "\n",
      "    http://lib.stat.cmu.edu/\n",
      "\n",
      "The data contains 20,640 observations on 9 variables.\n",
      "\n",
      "This dataset contains the average house value as target variable\n",
      "and the following input variables (features): average income,\n",
      "housing average age, average rooms, average bedrooms, population,\n",
      "average occupation, latitude, and longitude in that order.\n",
      "\n",
      "References\n",
      "----------\n",
      "\n",
      "Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "Statistics and Probability Letters, 33 (1997) 291-297.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "###### Do not modify here ###### \n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = graph_def\n",
    "    #strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "###### Do not modify  here ######\n",
    "\n",
    "###### Implement Data Preprocess here ######\n",
    "housing = fetch_california_housing()\n",
    "# Show description/ statisics about the dataset\n",
    "print(housing.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of training set: (18576, 8)\n",
      "Shape of testing set: (2064, 8)\n",
      "Shape of training label: (18576, 1)\n",
      "Shape of testing label: (2064, 1)\n"
     ]
    }
   ],
   "source": [
    "# Define cut point\n",
    "cut = int(housing.data.shape[0]*0.9)\n",
    "# Convert to column vector format, which is (n,1) not (n,)\n",
    "housing.target = housing.target.reshape(housing.target.shape[0],1)\n",
    "# Split dataset\n",
    "x_train, x_test = housing.data[:cut], housing.data[cut:]\n",
    "y_train, y_test = housing.target[:cut], housing.target[cut:]\n",
    "\n",
    "print(\"\\nShape of training set:\", x_train.shape)\n",
    "print(\"Shape of testing set:\", x_test.shape)\n",
    "print(\"Shape of training label:\", y_train.shape)\n",
    "print(\"Shape of testing label:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization & Include Bias to Weight Matrix\n",
    "\n",
    "(Useless in this case, it's linear transformation which can be solve in coeifficient calculation step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_ = np.concatenate((x_train,np.ones([x_train.shape[0],1])),axis=1)\n",
    "# x_test_  = np.concatenate((x_test ,np.ones([ x_test.shape[0],1])),axis=1)\n",
    "x_train_ = np.concatenate((np.divide(x_train - np.mean(x_train, axis=0, keepdims=True), np.std(x_train, axis=0, keepdims=True)),np.ones([x_train.shape[0],1])),axis=1)\n",
    "x_test_  = np.concatenate((np.divide(x_test  - np.mean(x_train, axis=0, keepdims=True), np.std(x_train, axis=0, keepdims=True)),np.ones([ x_test.shape[0],1])),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Define variables to take input feature x, label y\n",
    "x = tf.placeholder(tf.float32, shape = [None, x_train_.shape[1]], name=\"Input\")\n",
    "y = tf.placeholder(tf.float32, shape = [None, 1], name=\"Y\")\n",
    "W = tf.placeholder(tf.float32, shape = [x_train_.shape[1], 1], name=\"W\")\n",
    "\n",
    "# Calculate W\n",
    "XT = tf.matrix_transpose(x, name=\"X_Transpose\") # calculate transpose x\n",
    "W_train = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, x, name=\"XT_X\") , name=\"Inverse_XT_X\"),XT, name=\"Multiple_XT\"),y, name=\"Multiple_y\") # calculate w by formula\n",
    "\n",
    "# Systems of linear equation\n",
    "linear_regression = tf.matmul(x, W, name=\"Linear_Regression\")\n",
    "\n",
    "# Calculate the mean of error rate\n",
    "mean_error_rate = tf.reduce_mean(tf.divide(tf.abs(tf.subtract(y,linear_regression, name=\"Predict_Difference\")),y,name=\"Error_Rate\"), name=\"Mean_Error_Rate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Explain and Result\n",
    "\n",
    "To get the weight $W$ for linear equation \n",
    "\n",
    "$\\hat y = XW + b$\n",
    "\n",
    "We can utilizing following equation to solve it\n",
    "\n",
    "$W=(X^{(train)\\top} X^{(train)})^{-1} X^{(train)\\top} y^{(train)}$\n",
    "\n",
    "1. We set the placeholder to take the input feature as variable x and label as variable y, which corresponding to **Input** and **Y** in the graph below. Note that the x is original feature concatenate with 1 which represented the Bias $b$.\n",
    "\n",
    "2. To calculate the Weight $W$,\n",
    "\n",
    "    a. We calculate the element transpose X as variable XT which is **Inverse_XT_X** in graph.\n",
    "    \n",
    "    b. Calculate though the equation $W=(X^{(train)\\top} X^{(train)})^{-1} X^{(train)\\top} y^{(train)}$ to get W.\n",
    "    \n",
    "    c. By this step, we already get W for this systems of linear equation. Therefore, we are able to calculate the predict y via $XW$ as **Linear_Regression** in the graph.\n",
    "    \n",
    "    d. Finally, we calculte the mean error rate via $ \\frac{1}{m} \\sum \\frac{\\lvert(y -\\hat y) \\rvert}{y}$. which is the right-top part in the graph. Calculate the **Predict_Difference** via $y - \\hat y$, take absolute value (**Abs**), calculate **Error_Rate** ($y$ as denominator), then take the mean of error rate (**Mean_Error_Rate**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error Rate:  0.316861\n",
      " Testing Error Rate:  0.344206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.03947678975840341&quot;).pbtxt = 'node {\\n  name: &quot;Input&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 9\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 9\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;X_Transpose/transpose/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;X_Transpose/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;Input&quot;\\n  input: &quot;X_Transpose/transpose/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;XT_X&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X_Transpose/transpose&quot;\\n  input: &quot;Input&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Inverse_XT_X&quot;\\n  op: &quot;MatrixInverse&quot;\\n  input: &quot;XT_X&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adjoint&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Multiple_XT&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Inverse_XT_X&quot;\\n  input: &quot;X_Transpose/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Multiple_y&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Multiple_XT&quot;\\n  input: &quot;Y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Linear_Regression&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Input&quot;\\n  input: &quot;W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Predict_Difference&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Y&quot;\\n  input: &quot;Linear_Regression&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Abs&quot;\\n  op: &quot;Abs&quot;\\n  input: &quot;Predict_Difference&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Error_Rate&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;Abs&quot;\\n  input: &quot;Y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean_Error_Rate&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Error_Rate&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nversions {\\n  producer: 24\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.03947678975840341&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_w = np.ones((9,1),dtype=np.float64)\n",
    "with tf.Session() as sess:\n",
    "    ###### Start TF session ######\n",
    "    W_t = sess.run(W_train, {x: x_train_, y: y_train, W:init_w}) # Calculate W\n",
    "#     print(W_t)\n",
    "    print(\"Training Error Rate: \", sess.run(mean_error_rate, {x: x_train_, y: y_train, W:W_t}))\n",
    "    print(\" Testing Error Rate: \", sess.run(mean_error_rate, {x: x_test_, y: y_test, W:W_t}))\n",
    "    \n",
    "    show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import vincenty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pd = pd.DataFrame(x_train, columns=housing.feature_names)\n",
    "x_test_pd = pd.DataFrame(x_test, columns=housing.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = pd.DataFrame(x_train_pd.values, columns=housing.feature_names)\n",
    "x_test_data = pd.DataFrame(x_test_pd.values, columns=housing.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_coords = (36.778259, -119.417931)\n",
    "SF_coords = (37.773972, -122.431297)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance between the target and Los Angels\n",
    "x_train_data['Distance_LA'] = x_train_data.apply(lambda x: vincenty((x['Latitude'], x['Longitude']), LA_coords).miles, axis=1)\n",
    "x_test_data['Distance_LA'] = x_test_data.apply(lambda x: vincenty((x['Latitude'], x['Longitude']), LA_coords).miles, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18576, 10)\n",
      "(2064, 10)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the distance between the target and San Francisco\n",
    "x_train_data['Distance_SF'] = x_train_data.apply(lambda x: vincenty((x['Latitude'], x['Longitude']), SF_coords).miles, axis=1)\n",
    "x_test_data['Distance_SF'] = x_test_data.apply(lambda x: vincenty((x['Latitude'], x['Longitude']), SF_coords).miles, axis=1)\n",
    "print(x_train_data.shape)\n",
    "print(x_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear scaler + Polynominal (Final Result)\n",
    "\n",
    "Doesn't need to adding the bias, cause polynominal feature is already include it.\n",
    "Because Polynominal Feature will increase feature number, thus we need to modify the dimension in tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error Rate:  0.253196666012\n",
      "Testing Error Rate:  0.284491391691\n"
     ]
    }
   ],
   "source": [
    "normalizer = QuantileTransformer(n_quantiles=2)\n",
    "x_train__ = normalizer.fit_transform(x_train_data)\n",
    "x_test__ = normalizer.transform(x_test_data)\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "x_train__ = poly.fit_transform(x_train__)\n",
    "x_test__ = poly.transform(x_test__)\n",
    "\n",
    "# Clear graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Define variables to take input feature x, label y\n",
    "x = tf.placeholder(tf.float64, shape = [None, x_train__.shape[1]], name=\"Input\")\n",
    "y = tf.placeholder(tf.float64, shape = [None, 1], name=\"Y\")\n",
    "W = tf.placeholder(tf.float64, shape = [x_train__.shape[1], 1], name=\"W\")\n",
    "\n",
    "# Calculate W\n",
    "XT = tf.matrix_transpose(x, name=\"X_Transpose\") # calculate transpose x\n",
    "W_train = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, x, name=\"XT_X\") , name=\"Inverse_XT_X\"),XT, name=\"Multiple_XT\"),y, name=\"Multiple_y\") # calculate w by formula\n",
    "\n",
    "# Systems of linear equation\n",
    "linear_regression = tf.matmul(x, W, name=\"Linear_Regression\")\n",
    "\n",
    "# Calculate the mean of error rate\n",
    "mean_error_rate = tf.reduce_mean(tf.divide(tf.abs(tf.subtract(y,linear_regression, name=\"Predict_Difference\")),y,name=\"Error_Rate\"), name=\"Mean_Error_Rate\")\n",
    "\n",
    "init_w = np.ones((x_train__.shape[1],1),dtype=np.float32)\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    W_t = sess.run(W_train, {x: x_train__, y: y_train, W:init_w}) # Calculate W\n",
    "    \n",
    "    print(\"Train Error Rate: \", sess.run(mean_error_rate, {x: x_train__, y: y_train, W:W_t}))\n",
    "    print(\"Testing Error Rate: \", sess.run(mean_error_rate, {x: x_test__, y: y_test, W:W_t}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
