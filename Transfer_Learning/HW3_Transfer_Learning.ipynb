{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load data: digits 5 to 9, but still label with 0 to 4, \n",
    "# because TensorFlow expects label's integers from 0 to n_classes-1.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train2_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train2_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "X_valid2_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid2_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "X_test2 = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test2 = mnist.test.labels[mnist.test.labels >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we want to keep only 100 instances per class in the training set \n",
    "# and let's keep only 30 instances per class in the validation set\n",
    "# tesing set is already loaded above\n",
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)\n",
    "\n",
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Train Softmax Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Models/yen/mnist_5.ckpt\n",
      "   1 epochs,   Validation loss:1.52103,   Best loss:1.52103,   Accuracy:36.67%/ 41.56%\n",
      "   2 epochs,   Validation loss:1.51702,   Best loss:1.51702,   Accuracy:37.33%/ 42.05%\n",
      "   3 epochs,   Validation loss:1.51312,   Best loss:1.51312,   Accuracy:38.00%/ 42.42%\n",
      "   4 epochs,   Validation loss:1.50918,   Best loss:1.50918,   Accuracy:39.33%/ 42.97%\n",
      "   5 epochs,   Validation loss:1.50506,   Best loss:1.50506,   Accuracy:39.33%/ 43.16%\n",
      "   6 epochs,   Validation loss:1.50065,   Best loss:1.50065,   Accuracy:38.67%/ 43.43%\n",
      "   7 epochs,   Validation loss:1.49589,   Best loss:1.49589,   Accuracy:39.33%/ 43.65%\n",
      "   8 epochs,   Validation loss:1.49083,   Best loss:1.49083,   Accuracy:40.00%/ 43.92%\n",
      "   9 epochs,   Validation loss:1.48557,   Best loss:1.48557,   Accuracy:40.67%/ 44.15%\n",
      "  10 epochs,   Validation loss:1.48024,   Best loss:1.48024,   Accuracy:41.33%/ 44.44%\n",
      "  11 epochs,   Validation loss:1.47491,   Best loss:1.47491,   Accuracy:41.33%/ 44.79%\n",
      "  12 epochs,   Validation loss:1.46962,   Best loss:1.46962,   Accuracy:42.67%/ 45.13%\n",
      "  13 epochs,   Validation loss:1.46442,   Best loss:1.46442,   Accuracy:43.33%/ 45.53%\n",
      "  14 epochs,   Validation loss:1.45935,   Best loss:1.45935,   Accuracy:44.00%/ 45.77%\n",
      "  15 epochs,   Validation loss:1.45447,   Best loss:1.45447,   Accuracy:44.67%/ 45.94%\n",
      "  16 epochs,   Validation loss:1.44984,   Best loss:1.44984,   Accuracy:44.67%/ 46.25%\n",
      "  17 epochs,   Validation loss:1.44553,   Best loss:1.44553,   Accuracy:44.67%/ 46.64%\n",
      "  18 epochs,   Validation loss:1.44153,   Best loss:1.44153,   Accuracy:44.67%/ 46.68%\n",
      "  19 epochs,   Validation loss:1.43786,   Best loss:1.43786,   Accuracy:46.00%/ 47.13%\n",
      "  20 epochs,   Validation loss:1.43447,   Best loss:1.43447,   Accuracy:46.00%/ 47.38%\n",
      "  21 epochs,   Validation loss:1.43135,   Best loss:1.43135,   Accuracy:46.00%/ 47.52%\n",
      "  22 epochs,   Validation loss:1.42848,   Best loss:1.42848,   Accuracy:46.00%/ 47.58%\n",
      "  23 epochs,   Validation loss:1.42585,   Best loss:1.42585,   Accuracy:46.67%/ 47.64%\n",
      "  24 epochs,   Validation loss:1.42345,   Best loss:1.42345,   Accuracy:47.33%/ 47.83%\n",
      "  25 epochs,   Validation loss:1.42126,   Best loss:1.42126,   Accuracy:48.00%/ 47.99%\n",
      "  26 epochs,   Validation loss:1.41924,   Best loss:1.41924,   Accuracy:48.00%/ 48.04%\n",
      "  27 epochs,   Validation loss:1.41735,   Best loss:1.41735,   Accuracy:48.00%/ 48.24%\n",
      "  28 epochs,   Validation loss:1.41553,   Best loss:1.41553,   Accuracy:48.00%/ 48.41%\n",
      "  29 epochs,   Validation loss:1.41374,   Best loss:1.41374,   Accuracy:48.00%/ 48.55%\n",
      "  30 epochs,   Validation loss:1.41190,   Best loss:1.41190,   Accuracy:48.67%/ 48.67%\n",
      "  31 epochs,   Validation loss:1.40996,   Best loss:1.40996,   Accuracy:48.67%/ 48.82%\n",
      "  32 epochs,   Validation loss:1.40782,   Best loss:1.40782,   Accuracy:48.67%/ 49.04%\n",
      "  33 epochs,   Validation loss:1.40535,   Best loss:1.40535,   Accuracy:48.67%/ 49.25%\n",
      "  34 epochs,   Validation loss:1.40240,   Best loss:1.40240,   Accuracy:48.67%/ 49.48%\n",
      "  35 epochs,   Validation loss:1.39883,   Best loss:1.39883,   Accuracy:49.33%/ 49.58%\n",
      "  36 epochs,   Validation loss:1.39451,   Best loss:1.39451,   Accuracy:49.33%/ 49.83%\n",
      "  37 epochs,   Validation loss:1.38947,   Best loss:1.38947,   Accuracy:50.00%/ 49.87%\n",
      "  38 epochs,   Validation loss:1.38390,   Best loss:1.38390,   Accuracy:50.00%/ 50.01%\n",
      "  39 epochs,   Validation loss:1.37816,   Best loss:1.37816,   Accuracy:52.67%/ 50.20%\n",
      "  40 epochs,   Validation loss:1.37257,   Best loss:1.37257,   Accuracy:53.33%/ 50.36%\n",
      "  41 epochs,   Validation loss:1.36725,   Best loss:1.36725,   Accuracy:53.33%/ 50.73%\n",
      "  42 epochs,   Validation loss:1.36213,   Best loss:1.36213,   Accuracy:53.33%/ 51.08%\n",
      "  43 epochs,   Validation loss:1.35716,   Best loss:1.35716,   Accuracy:54.00%/ 51.39%\n",
      "  44 epochs,   Validation loss:1.35249,   Best loss:1.35249,   Accuracy:54.67%/ 51.90%\n",
      "  45 epochs,   Validation loss:1.34834,   Best loss:1.34834,   Accuracy:55.33%/ 52.33%\n",
      "  46 epochs,   Validation loss:1.34467,   Best loss:1.34467,   Accuracy:55.33%/ 52.68%\n",
      "  47 epochs,   Validation loss:1.34107,   Best loss:1.34107,   Accuracy:55.33%/ 53.03%\n",
      "  48 epochs,   Validation loss:1.33703,   Best loss:1.33703,   Accuracy:55.33%/ 53.43%\n",
      "  49 epochs,   Validation loss:1.33235,   Best loss:1.33235,   Accuracy:56.67%/ 53.77%\n",
      "  50 epochs,   Validation loss:1.32725,   Best loss:1.32725,   Accuracy:57.33%/ 54.29%\n",
      "  51 epochs,   Validation loss:1.32188,   Best loss:1.32188,   Accuracy:58.00%/ 54.82%\n",
      "  52 epochs,   Validation loss:1.31664,   Best loss:1.31664,   Accuracy:59.33%/ 55.21%\n",
      "  53 epochs,   Validation loss:1.31222,   Best loss:1.31222,   Accuracy:59.33%/ 55.50%\n",
      "  54 epochs,   Validation loss:1.30847,   Best loss:1.30847,   Accuracy:58.67%/ 56.14%\n",
      "  55 epochs,   Validation loss:1.30486,   Best loss:1.30486,   Accuracy:59.33%/ 56.72%\n",
      "  56 epochs,   Validation loss:1.30109,   Best loss:1.30109,   Accuracy:59.33%/ 57.21%\n",
      "  57 epochs,   Validation loss:1.29697,   Best loss:1.29697,   Accuracy:58.67%/ 57.56%\n",
      "  58 epochs,   Validation loss:1.29231,   Best loss:1.29231,   Accuracy:59.33%/ 58.22%\n",
      "  59 epochs,   Validation loss:1.28676,   Best loss:1.28676,   Accuracy:60.00%/ 58.73%\n",
      "  60 epochs,   Validation loss:1.27995,   Best loss:1.27995,   Accuracy:61.33%/ 59.35%\n",
      "  61 epochs,   Validation loss:1.27175,   Best loss:1.27175,   Accuracy:63.33%/ 60.03%\n",
      "  62 epochs,   Validation loss:1.26271,   Best loss:1.26271,   Accuracy:64.67%/ 60.56%\n",
      "  63 epochs,   Validation loss:1.25406,   Best loss:1.25406,   Accuracy:65.33%/ 61.00%\n",
      "  64 epochs,   Validation loss:1.24684,   Best loss:1.24684,   Accuracy:66.67%/ 61.65%\n",
      "  65 epochs,   Validation loss:1.24116,   Best loss:1.24116,   Accuracy:66.67%/ 62.13%\n",
      "  66 epochs,   Validation loss:1.23651,   Best loss:1.23651,   Accuracy:66.67%/ 62.62%\n",
      "  67 epochs,   Validation loss:1.23249,   Best loss:1.23249,   Accuracy:67.33%/ 63.16%\n",
      "  68 epochs,   Validation loss:1.22895,   Best loss:1.22895,   Accuracy:68.00%/ 63.65%\n",
      "  69 epochs,   Validation loss:1.22587,   Best loss:1.22587,   Accuracy:68.67%/ 63.81%\n",
      "  70 epochs,   Validation loss:1.22322,   Best loss:1.22322,   Accuracy:68.67%/ 64.18%\n",
      "  71 epochs,   Validation loss:1.22097,   Best loss:1.22097,   Accuracy:68.67%/ 64.64%\n",
      "  72 epochs,   Validation loss:1.21904,   Best loss:1.21904,   Accuracy:68.67%/ 64.97%\n",
      "  73 epochs,   Validation loss:1.21735,   Best loss:1.21735,   Accuracy:69.33%/ 65.46%\n",
      "  74 epochs,   Validation loss:1.21584,   Best loss:1.21584,   Accuracy:70.00%/ 65.77%\n",
      "  75 epochs,   Validation loss:1.21450,   Best loss:1.21450,   Accuracy:70.00%/ 66.12%\n",
      "  76 epochs,   Validation loss:1.21343,   Best loss:1.21343,   Accuracy:71.33%/ 66.61%\n",
      "  77 epochs,   Validation loss:1.21273,   Best loss:1.21273,   Accuracy:71.33%/ 66.84%\n",
      "  78 epochs,   Validation loss:1.21239,   Best loss:1.21239,   Accuracy:70.67%/ 67.02%\n",
      "  79 epochs,   Validation loss:1.21227,   Best loss:1.21227,   Accuracy:70.67%/ 67.15%\n",
      "  80 epochs,   Validation loss:1.21224,   Best loss:1.21224,   Accuracy:70.67%/ 67.31%\n",
      "  81 epochs,   Validation loss:1.21218,   Best loss:1.21218,   Accuracy:70.67%/ 67.62%\n",
      "  82 epochs,   Validation loss:1.21200,   Best loss:1.21200,   Accuracy:70.67%/ 67.87%\n",
      "  83 epochs,   Validation loss:1.21165,   Best loss:1.21165,   Accuracy:70.67%/ 67.95%\n",
      "  84 epochs,   Validation loss:1.21112,   Best loss:1.21112,   Accuracy:70.67%/ 68.11%\n",
      "  85 epochs,   Validation loss:1.21041,   Best loss:1.21041,   Accuracy:70.67%/ 68.13%\n",
      "  86 epochs,   Validation loss:1.20953,   Best loss:1.20953,   Accuracy:70.67%/ 68.26%\n",
      "  87 epochs,   Validation loss:1.20849,   Best loss:1.20849,   Accuracy:71.33%/ 68.30%\n",
      "  88 epochs,   Validation loss:1.20733,   Best loss:1.20733,   Accuracy:71.33%/ 68.44%\n",
      "  89 epochs,   Validation loss:1.20605,   Best loss:1.20605,   Accuracy:71.33%/ 68.50%\n",
      "  90 epochs,   Validation loss:1.20469,   Best loss:1.20469,   Accuracy:71.33%/ 68.63%\n",
      "  91 epochs,   Validation loss:1.20325,   Best loss:1.20325,   Accuracy:70.67%/ 68.59%\n",
      "  92 epochs,   Validation loss:1.20175,   Best loss:1.20175,   Accuracy:70.67%/ 68.67%\n",
      "  93 epochs,   Validation loss:1.20021,   Best loss:1.20021,   Accuracy:70.67%/ 68.71%\n",
      "  94 epochs,   Validation loss:1.19866,   Best loss:1.19866,   Accuracy:70.67%/ 68.71%\n",
      "  95 epochs,   Validation loss:1.19713,   Best loss:1.19713,   Accuracy:70.67%/ 68.90%\n",
      "  96 epochs,   Validation loss:1.19564,   Best loss:1.19564,   Accuracy:70.67%/ 69.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  97 epochs,   Validation loss:1.19423,   Best loss:1.19423,   Accuracy:72.00%/ 69.31%\n",
      "  98 epochs,   Validation loss:1.19291,   Best loss:1.19291,   Accuracy:72.00%/ 69.37%\n",
      "  99 epochs,   Validation loss:1.19169,   Best loss:1.19169,   Accuracy:72.00%/ 69.47%\n",
      " 100 epochs,   Validation loss:1.19056,   Best loss:1.19056,   Accuracy:73.33%/ 69.51%\n",
      " 101 epochs,   Validation loss:1.18951,   Best loss:1.18951,   Accuracy:73.33%/ 69.59%\n",
      " 102 epochs,   Validation loss:1.18849,   Best loss:1.18849,   Accuracy:74.00%/ 69.80%\n",
      " 103 epochs,   Validation loss:1.18748,   Best loss:1.18748,   Accuracy:74.00%/ 69.90%\n",
      " 104 epochs,   Validation loss:1.18643,   Best loss:1.18643,   Accuracy:74.00%/ 69.97%\n",
      " 105 epochs,   Validation loss:1.18534,   Best loss:1.18534,   Accuracy:74.00%/ 70.09%\n",
      " 106 epochs,   Validation loss:1.18418,   Best loss:1.18418,   Accuracy:74.00%/ 70.25%\n",
      " 107 epochs,   Validation loss:1.18297,   Best loss:1.18297,   Accuracy:74.00%/ 70.36%\n",
      " 108 epochs,   Validation loss:1.18172,   Best loss:1.18172,   Accuracy:74.00%/ 70.54%\n",
      " 109 epochs,   Validation loss:1.18047,   Best loss:1.18047,   Accuracy:74.00%/ 70.71%\n",
      " 110 epochs,   Validation loss:1.17924,   Best loss:1.17924,   Accuracy:74.67%/ 70.77%\n",
      " 111 epochs,   Validation loss:1.17805,   Best loss:1.17805,   Accuracy:74.67%/ 70.91%\n",
      " 112 epochs,   Validation loss:1.17693,   Best loss:1.17693,   Accuracy:74.67%/ 71.10%\n",
      " 113 epochs,   Validation loss:1.17589,   Best loss:1.17589,   Accuracy:74.67%/ 71.28%\n",
      " 114 epochs,   Validation loss:1.17494,   Best loss:1.17494,   Accuracy:74.67%/ 71.30%\n",
      " 115 epochs,   Validation loss:1.17407,   Best loss:1.17407,   Accuracy:74.67%/ 71.47%\n",
      " 116 epochs,   Validation loss:1.17328,   Best loss:1.17328,   Accuracy:74.67%/ 71.61%\n",
      " 117 epochs,   Validation loss:1.17256,   Best loss:1.17256,   Accuracy:74.67%/ 71.67%\n",
      " 118 epochs,   Validation loss:1.17189,   Best loss:1.17189,   Accuracy:74.67%/ 71.86%\n",
      " 119 epochs,   Validation loss:1.17126,   Best loss:1.17126,   Accuracy:74.67%/ 71.92%\n",
      " 120 epochs,   Validation loss:1.17064,   Best loss:1.17064,   Accuracy:74.00%/ 71.94%\n",
      " 121 epochs,   Validation loss:1.17002,   Best loss:1.17002,   Accuracy:74.00%/ 72.00%\n",
      " 122 epochs,   Validation loss:1.16937,   Best loss:1.16937,   Accuracy:74.00%/ 72.17%\n",
      " 123 epochs,   Validation loss:1.16865,   Best loss:1.16865,   Accuracy:74.00%/ 72.25%\n",
      " 124 epochs,   Validation loss:1.16786,   Best loss:1.16786,   Accuracy:74.00%/ 72.37%\n",
      " 125 epochs,   Validation loss:1.16698,   Best loss:1.16698,   Accuracy:74.00%/ 72.43%\n",
      " 126 epochs,   Validation loss:1.16598,   Best loss:1.16598,   Accuracy:74.00%/ 72.58%\n",
      " 127 epochs,   Validation loss:1.16488,   Best loss:1.16488,   Accuracy:74.00%/ 72.64%\n",
      " 128 epochs,   Validation loss:1.16367,   Best loss:1.16367,   Accuracy:74.00%/ 72.78%\n",
      " 129 epochs,   Validation loss:1.16236,   Best loss:1.16236,   Accuracy:74.67%/ 72.99%\n",
      "\n",
      "Training Time:86.665806\n"
     ]
    }
   ],
   "source": [
    "reset_graph() # clean the graph\n",
    "\n",
    "no_update_tolerant = 20 # set the criteria that if the model didn't get better for how many epochs\n",
    "\n",
    "no_update_progress = 0 # the variables to record for the not better epochs\n",
    "current_best_accuracy = 0.0 # variables to record the best valid accuracy\n",
    "current_best_loss = 10.0 # variables to record the best valid loss\n",
    "\n",
    "\n",
    "with tf.Session() as sess: # start the tensorflow nn session\n",
    "    restore_saver = tf.train.import_meta_graph(\"./Models/yen/mnist_5.ckpt.meta\") # load meta graph\n",
    "    restore_saver.restore(sess, tf.train.latest_checkpoint('./Models/yen/')) # restore weights\n",
    "\n",
    "    saver = tf.train.Saver() # to store the model\n",
    "    \"\"\"\n",
    "    Graph Define Step\n",
    "    \n",
    "    1. Restore the variable about the component in graph which help to retrieve and assign value\n",
    "    \"\"\"\n",
    "    graph = tf.get_default_graph() # get original graph\n",
    "    X = graph.get_tensor_by_name(\"Input_X:0\") # assign placeholder variables with input X\n",
    "    y = graph.get_tensor_by_name(\"Input_Label:0\")# assign placeholder variables with input Label\n",
    "    loss = graph.get_tensor_by_name(\"Loss:0\") # assign variables about loss\n",
    "    Y_proba = graph.get_tensor_by_name(\"Softmax_Layer/Softmax:0\") # assign variables about loss\n",
    "    accuracy = graph.get_tensor_by_name(\"Accuracy:0\") # assign variables  about accuracy\n",
    "\n",
    "    \"\"\"\n",
    "    2. Get the softmax layer which is what we would like to train\n",
    "    \"\"\"\n",
    "    output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"Softmax_Layer\") # get softmax layer by scope name\n",
    "    \n",
    "    \"\"\"\n",
    "    3. Define the optimizer and assign to only update on softmax_layer which defined above\n",
    "    \"\"\"\n",
    "    optimizer = tf.train.AdamOptimizer(0.0017, name=\"Adam_Op\") # create a new optimizer\n",
    "    training_op = optimizer.minimize(loss, var_list=output_layer_vars) # minimize the loss and only update certern variables\n",
    "    var_list_init = tf.variables_initializer([optimizer.get_slot(var, name) for name in optimizer.get_slot_names() for var in output_layer_vars]+list(optimizer._get_beta_accumulators())) # to get the variables name about the softmax layer and \n",
    "    sess.run(var_list_init) # initialize the un-initizlized variables\n",
    "    \"\"\"\n",
    "    Training Step\n",
    "    \"\"\"\n",
    "    begin_time = time.time() # record the begin training time\n",
    "    for epochs in range(1000): # training on 1000 epochs\n",
    "        _, train_loss = sess.run([training_op, loss], feed_dict={X:X_train2, y:y_train2}) # feed with training variables\n",
    "        valid_loss, valid_accuracy = sess.run([loss, accuracy], feed_dict={X:X_valid2, y:y_valid2}) # feed with validation variables\n",
    "        test_loss ,  test_accuracy = sess.run([loss, accuracy], feed_dict={X:X_test2, y:y_test2}) # feed with testing variables\n",
    "        \n",
    "        if valid_accuracy > current_best_accuracy: # if better\n",
    "            current_best_accuracy = valid_accuracy # keep record\n",
    "            save_path = saver.save(sess, \"./Models/TransferLearning/HW3_1/Team26_HW3_1.ckpt\") #keep the best model\n",
    "            no_update_progress = 0\n",
    "        else:                                      # if not better\n",
    "            no_update_progress += 1                # record on no update\n",
    "\n",
    "        if valid_loss < current_best_loss: # if better\n",
    "            current_best_loss = valid_loss # keep record       \n",
    "            \n",
    "        if no_update_progress == no_update_tolerant: break # stop training\n",
    "            \n",
    "                \n",
    "        print(\"{:4d} epochs,   Validation loss:{:.5f},   Best loss:{:.5f},   Accuracy:{:.2f}%/ {:.2f}%\".format(\n",
    "            epochs+1,\n",
    "            valid_loss,\n",
    "            current_best_loss,                                                                                       \n",
    "            valid_accuracy*100,\n",
    "            test_accuracy*100\n",
    "        )) # print the performane for each epochs\n",
    "    finish_itme = time.time() # record the finish time\n",
    "    print(\"\\nTraining Time:{:3f}\".format(finish_itme-begin_time)) # calculate and print training time\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Cache the Output of FIfth layer for Speed Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Models/yen/mnist_5.ckpt\n",
      "   1 epochs,   Validation loss:1.52103,   Best loss:1.52103,   Accuracy:36.67%/ 41.56%\n",
      "   2 epochs,   Validation loss:1.51702,   Best loss:1.51702,   Accuracy:37.33%/ 42.05%\n",
      "   3 epochs,   Validation loss:1.51312,   Best loss:1.51312,   Accuracy:38.00%/ 42.42%\n",
      "   4 epochs,   Validation loss:1.50918,   Best loss:1.50918,   Accuracy:39.33%/ 42.97%\n",
      "   5 epochs,   Validation loss:1.50506,   Best loss:1.50506,   Accuracy:39.33%/ 43.16%\n",
      "   6 epochs,   Validation loss:1.50065,   Best loss:1.50065,   Accuracy:38.67%/ 43.43%\n",
      "   7 epochs,   Validation loss:1.49589,   Best loss:1.49589,   Accuracy:39.33%/ 43.65%\n",
      "   8 epochs,   Validation loss:1.49083,   Best loss:1.49083,   Accuracy:40.00%/ 43.92%\n",
      "   9 epochs,   Validation loss:1.48557,   Best loss:1.48557,   Accuracy:40.67%/ 44.15%\n",
      "  10 epochs,   Validation loss:1.48024,   Best loss:1.48024,   Accuracy:41.33%/ 44.44%\n",
      "  11 epochs,   Validation loss:1.47491,   Best loss:1.47491,   Accuracy:41.33%/ 44.79%\n",
      "  12 epochs,   Validation loss:1.46962,   Best loss:1.46962,   Accuracy:42.67%/ 45.13%\n",
      "  13 epochs,   Validation loss:1.46442,   Best loss:1.46442,   Accuracy:43.33%/ 45.53%\n",
      "  14 epochs,   Validation loss:1.45935,   Best loss:1.45935,   Accuracy:44.00%/ 45.77%\n",
      "  15 epochs,   Validation loss:1.45447,   Best loss:1.45447,   Accuracy:44.67%/ 45.94%\n",
      "  16 epochs,   Validation loss:1.44984,   Best loss:1.44984,   Accuracy:44.67%/ 46.25%\n",
      "  17 epochs,   Validation loss:1.44553,   Best loss:1.44553,   Accuracy:44.67%/ 46.64%\n",
      "  18 epochs,   Validation loss:1.44153,   Best loss:1.44153,   Accuracy:44.67%/ 46.68%\n",
      "  19 epochs,   Validation loss:1.43786,   Best loss:1.43786,   Accuracy:46.00%/ 47.13%\n",
      "  20 epochs,   Validation loss:1.43447,   Best loss:1.43447,   Accuracy:46.00%/ 47.38%\n",
      "  21 epochs,   Validation loss:1.43135,   Best loss:1.43135,   Accuracy:46.00%/ 47.52%\n",
      "  22 epochs,   Validation loss:1.42848,   Best loss:1.42848,   Accuracy:46.00%/ 47.58%\n",
      "  23 epochs,   Validation loss:1.42585,   Best loss:1.42585,   Accuracy:46.67%/ 47.64%\n",
      "  24 epochs,   Validation loss:1.42345,   Best loss:1.42345,   Accuracy:47.33%/ 47.83%\n",
      "  25 epochs,   Validation loss:1.42126,   Best loss:1.42126,   Accuracy:48.00%/ 47.99%\n",
      "  26 epochs,   Validation loss:1.41924,   Best loss:1.41924,   Accuracy:48.00%/ 48.04%\n",
      "  27 epochs,   Validation loss:1.41735,   Best loss:1.41735,   Accuracy:48.00%/ 48.24%\n",
      "  28 epochs,   Validation loss:1.41553,   Best loss:1.41553,   Accuracy:48.00%/ 48.41%\n",
      "  29 epochs,   Validation loss:1.41374,   Best loss:1.41374,   Accuracy:48.00%/ 48.55%\n",
      "  30 epochs,   Validation loss:1.41190,   Best loss:1.41190,   Accuracy:48.67%/ 48.67%\n",
      "  31 epochs,   Validation loss:1.40996,   Best loss:1.40996,   Accuracy:48.67%/ 48.82%\n",
      "  32 epochs,   Validation loss:1.40782,   Best loss:1.40782,   Accuracy:48.67%/ 49.04%\n",
      "  33 epochs,   Validation loss:1.40535,   Best loss:1.40535,   Accuracy:48.67%/ 49.25%\n",
      "  34 epochs,   Validation loss:1.40240,   Best loss:1.40240,   Accuracy:48.67%/ 49.48%\n",
      "  35 epochs,   Validation loss:1.39883,   Best loss:1.39883,   Accuracy:49.33%/ 49.58%\n",
      "  36 epochs,   Validation loss:1.39451,   Best loss:1.39451,   Accuracy:49.33%/ 49.83%\n",
      "  37 epochs,   Validation loss:1.38947,   Best loss:1.38947,   Accuracy:50.00%/ 49.87%\n",
      "  38 epochs,   Validation loss:1.38390,   Best loss:1.38390,   Accuracy:50.00%/ 50.01%\n",
      "  39 epochs,   Validation loss:1.37816,   Best loss:1.37816,   Accuracy:52.67%/ 50.20%\n",
      "  40 epochs,   Validation loss:1.37257,   Best loss:1.37257,   Accuracy:53.33%/ 50.36%\n",
      "  41 epochs,   Validation loss:1.36725,   Best loss:1.36725,   Accuracy:53.33%/ 50.73%\n",
      "  42 epochs,   Validation loss:1.36213,   Best loss:1.36213,   Accuracy:53.33%/ 51.08%\n",
      "  43 epochs,   Validation loss:1.35716,   Best loss:1.35716,   Accuracy:54.00%/ 51.39%\n",
      "  44 epochs,   Validation loss:1.35249,   Best loss:1.35249,   Accuracy:54.67%/ 51.90%\n",
      "  45 epochs,   Validation loss:1.34834,   Best loss:1.34834,   Accuracy:55.33%/ 52.33%\n",
      "  46 epochs,   Validation loss:1.34467,   Best loss:1.34467,   Accuracy:55.33%/ 52.68%\n",
      "  47 epochs,   Validation loss:1.34107,   Best loss:1.34107,   Accuracy:55.33%/ 53.03%\n",
      "  48 epochs,   Validation loss:1.33703,   Best loss:1.33703,   Accuracy:55.33%/ 53.43%\n",
      "  49 epochs,   Validation loss:1.33235,   Best loss:1.33235,   Accuracy:56.67%/ 53.77%\n",
      "  50 epochs,   Validation loss:1.32725,   Best loss:1.32725,   Accuracy:57.33%/ 54.29%\n",
      "  51 epochs,   Validation loss:1.32188,   Best loss:1.32188,   Accuracy:58.00%/ 54.82%\n",
      "  52 epochs,   Validation loss:1.31664,   Best loss:1.31664,   Accuracy:59.33%/ 55.21%\n",
      "  53 epochs,   Validation loss:1.31222,   Best loss:1.31222,   Accuracy:59.33%/ 55.50%\n",
      "  54 epochs,   Validation loss:1.30847,   Best loss:1.30847,   Accuracy:58.67%/ 56.14%\n",
      "  55 epochs,   Validation loss:1.30486,   Best loss:1.30486,   Accuracy:59.33%/ 56.72%\n",
      "  56 epochs,   Validation loss:1.30109,   Best loss:1.30109,   Accuracy:59.33%/ 57.21%\n",
      "  57 epochs,   Validation loss:1.29697,   Best loss:1.29697,   Accuracy:58.67%/ 57.56%\n",
      "  58 epochs,   Validation loss:1.29231,   Best loss:1.29231,   Accuracy:59.33%/ 58.22%\n",
      "  59 epochs,   Validation loss:1.28676,   Best loss:1.28676,   Accuracy:60.00%/ 58.73%\n",
      "  60 epochs,   Validation loss:1.27995,   Best loss:1.27995,   Accuracy:61.33%/ 59.35%\n",
      "  61 epochs,   Validation loss:1.27175,   Best loss:1.27175,   Accuracy:63.33%/ 60.03%\n",
      "  62 epochs,   Validation loss:1.26271,   Best loss:1.26271,   Accuracy:64.67%/ 60.56%\n",
      "  63 epochs,   Validation loss:1.25406,   Best loss:1.25406,   Accuracy:65.33%/ 61.00%\n",
      "  64 epochs,   Validation loss:1.24684,   Best loss:1.24684,   Accuracy:66.67%/ 61.65%\n",
      "  65 epochs,   Validation loss:1.24116,   Best loss:1.24116,   Accuracy:66.67%/ 62.13%\n",
      "  66 epochs,   Validation loss:1.23651,   Best loss:1.23651,   Accuracy:66.67%/ 62.62%\n",
      "  67 epochs,   Validation loss:1.23249,   Best loss:1.23249,   Accuracy:67.33%/ 63.16%\n",
      "  68 epochs,   Validation loss:1.22895,   Best loss:1.22895,   Accuracy:68.00%/ 63.65%\n",
      "  69 epochs,   Validation loss:1.22587,   Best loss:1.22587,   Accuracy:68.67%/ 63.81%\n",
      "  70 epochs,   Validation loss:1.22322,   Best loss:1.22322,   Accuracy:68.67%/ 64.18%\n",
      "  71 epochs,   Validation loss:1.22097,   Best loss:1.22097,   Accuracy:68.67%/ 64.64%\n",
      "  72 epochs,   Validation loss:1.21904,   Best loss:1.21904,   Accuracy:68.67%/ 64.97%\n",
      "  73 epochs,   Validation loss:1.21735,   Best loss:1.21735,   Accuracy:69.33%/ 65.46%\n",
      "  74 epochs,   Validation loss:1.21584,   Best loss:1.21584,   Accuracy:70.00%/ 65.77%\n",
      "  75 epochs,   Validation loss:1.21450,   Best loss:1.21450,   Accuracy:70.00%/ 66.12%\n",
      "  76 epochs,   Validation loss:1.21343,   Best loss:1.21343,   Accuracy:71.33%/ 66.61%\n",
      "  77 epochs,   Validation loss:1.21273,   Best loss:1.21273,   Accuracy:71.33%/ 66.84%\n",
      "  78 epochs,   Validation loss:1.21239,   Best loss:1.21239,   Accuracy:70.67%/ 67.02%\n",
      "  79 epochs,   Validation loss:1.21227,   Best loss:1.21227,   Accuracy:70.67%/ 67.15%\n",
      "  80 epochs,   Validation loss:1.21224,   Best loss:1.21224,   Accuracy:70.67%/ 67.31%\n",
      "  81 epochs,   Validation loss:1.21218,   Best loss:1.21218,   Accuracy:70.67%/ 67.62%\n",
      "  82 epochs,   Validation loss:1.21200,   Best loss:1.21200,   Accuracy:70.67%/ 67.87%\n",
      "  83 epochs,   Validation loss:1.21165,   Best loss:1.21165,   Accuracy:70.67%/ 67.95%\n",
      "  84 epochs,   Validation loss:1.21112,   Best loss:1.21112,   Accuracy:70.67%/ 68.11%\n",
      "  85 epochs,   Validation loss:1.21041,   Best loss:1.21041,   Accuracy:70.67%/ 68.13%\n",
      "  86 epochs,   Validation loss:1.20953,   Best loss:1.20953,   Accuracy:70.67%/ 68.26%\n",
      "  87 epochs,   Validation loss:1.20849,   Best loss:1.20849,   Accuracy:71.33%/ 68.30%\n",
      "  88 epochs,   Validation loss:1.20733,   Best loss:1.20733,   Accuracy:71.33%/ 68.44%\n",
      "  89 epochs,   Validation loss:1.20605,   Best loss:1.20605,   Accuracy:71.33%/ 68.50%\n",
      "  90 epochs,   Validation loss:1.20469,   Best loss:1.20469,   Accuracy:71.33%/ 68.63%\n",
      "  91 epochs,   Validation loss:1.20325,   Best loss:1.20325,   Accuracy:70.67%/ 68.59%\n",
      "  92 epochs,   Validation loss:1.20175,   Best loss:1.20175,   Accuracy:70.67%/ 68.67%\n",
      "  93 epochs,   Validation loss:1.20021,   Best loss:1.20021,   Accuracy:70.67%/ 68.71%\n",
      "  94 epochs,   Validation loss:1.19866,   Best loss:1.19866,   Accuracy:70.67%/ 68.71%\n",
      "  95 epochs,   Validation loss:1.19713,   Best loss:1.19713,   Accuracy:70.67%/ 68.90%\n",
      "  96 epochs,   Validation loss:1.19564,   Best loss:1.19564,   Accuracy:70.67%/ 69.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  97 epochs,   Validation loss:1.19423,   Best loss:1.19423,   Accuracy:72.00%/ 69.31%\n",
      "  98 epochs,   Validation loss:1.19291,   Best loss:1.19291,   Accuracy:72.00%/ 69.37%\n",
      "  99 epochs,   Validation loss:1.19169,   Best loss:1.19169,   Accuracy:72.00%/ 69.47%\n",
      " 100 epochs,   Validation loss:1.19056,   Best loss:1.19056,   Accuracy:73.33%/ 69.51%\n",
      " 101 epochs,   Validation loss:1.18951,   Best loss:1.18951,   Accuracy:73.33%/ 69.59%\n",
      " 102 epochs,   Validation loss:1.18849,   Best loss:1.18849,   Accuracy:74.00%/ 69.80%\n",
      " 103 epochs,   Validation loss:1.18748,   Best loss:1.18748,   Accuracy:74.00%/ 69.90%\n",
      " 104 epochs,   Validation loss:1.18643,   Best loss:1.18643,   Accuracy:74.00%/ 69.97%\n",
      " 105 epochs,   Validation loss:1.18534,   Best loss:1.18534,   Accuracy:74.00%/ 70.09%\n",
      " 106 epochs,   Validation loss:1.18418,   Best loss:1.18418,   Accuracy:74.00%/ 70.25%\n",
      " 107 epochs,   Validation loss:1.18297,   Best loss:1.18297,   Accuracy:74.00%/ 70.36%\n",
      " 108 epochs,   Validation loss:1.18172,   Best loss:1.18172,   Accuracy:74.00%/ 70.54%\n",
      " 109 epochs,   Validation loss:1.18047,   Best loss:1.18047,   Accuracy:74.00%/ 70.71%\n",
      " 110 epochs,   Validation loss:1.17924,   Best loss:1.17924,   Accuracy:74.67%/ 70.77%\n",
      " 111 epochs,   Validation loss:1.17805,   Best loss:1.17805,   Accuracy:74.67%/ 70.91%\n",
      " 112 epochs,   Validation loss:1.17693,   Best loss:1.17693,   Accuracy:74.67%/ 71.10%\n",
      " 113 epochs,   Validation loss:1.17589,   Best loss:1.17589,   Accuracy:74.67%/ 71.28%\n",
      " 114 epochs,   Validation loss:1.17494,   Best loss:1.17494,   Accuracy:74.67%/ 71.30%\n",
      " 115 epochs,   Validation loss:1.17407,   Best loss:1.17407,   Accuracy:74.67%/ 71.47%\n",
      " 116 epochs,   Validation loss:1.17328,   Best loss:1.17328,   Accuracy:74.67%/ 71.61%\n",
      " 117 epochs,   Validation loss:1.17256,   Best loss:1.17256,   Accuracy:74.67%/ 71.67%\n",
      " 118 epochs,   Validation loss:1.17189,   Best loss:1.17189,   Accuracy:74.67%/ 71.86%\n",
      " 119 epochs,   Validation loss:1.17126,   Best loss:1.17126,   Accuracy:74.67%/ 71.92%\n",
      " 120 epochs,   Validation loss:1.17064,   Best loss:1.17064,   Accuracy:74.00%/ 71.94%\n",
      " 121 epochs,   Validation loss:1.17002,   Best loss:1.17002,   Accuracy:74.00%/ 72.00%\n",
      " 122 epochs,   Validation loss:1.16937,   Best loss:1.16937,   Accuracy:74.00%/ 72.17%\n",
      " 123 epochs,   Validation loss:1.16865,   Best loss:1.16865,   Accuracy:74.00%/ 72.25%\n",
      " 124 epochs,   Validation loss:1.16786,   Best loss:1.16786,   Accuracy:74.00%/ 72.37%\n",
      " 125 epochs,   Validation loss:1.16698,   Best loss:1.16698,   Accuracy:74.00%/ 72.43%\n",
      " 126 epochs,   Validation loss:1.16598,   Best loss:1.16598,   Accuracy:74.00%/ 72.58%\n",
      " 127 epochs,   Validation loss:1.16488,   Best loss:1.16488,   Accuracy:74.00%/ 72.64%\n",
      " 128 epochs,   Validation loss:1.16367,   Best loss:1.16367,   Accuracy:74.00%/ 72.78%\n",
      " 129 epochs,   Validation loss:1.16236,   Best loss:1.16236,   Accuracy:74.67%/ 72.99%\n",
      "\n",
      "Training Time:83.261949\n"
     ]
    }
   ],
   "source": [
    "reset_graph() # clean the graph\n",
    "\n",
    "no_update_tolerant = 20 # set the criteria that if the model didn't get better for how many epochs\n",
    "\n",
    "no_update_progress = 0 # the variables to record for the not better epochs\n",
    "current_best_accuracy = 0.0 # variables to record the best valid accuracy\n",
    "current_best_loss = 10.0 # variables to record the best valid loss\n",
    "\n",
    "with tf.Session() as sess: # start the tensorflow nn session\n",
    "    restore_saver = tf.train.import_meta_graph(\"./Models/yen/mnist_5.ckpt.meta\") # load meta graph\n",
    "    restore_saver.restore(sess, tf.train.latest_checkpoint('./Models/yen/')) # restore weights\n",
    "\n",
    "    saver = tf.train.Saver() # to store the model\n",
    "    \"\"\"\n",
    "    Graph Define Step\n",
    "    \n",
    "    1. Restore the variable about the component in graph which help to retrieve and assign value\n",
    "    \"\"\"\n",
    "    graph = tf.get_default_graph() # get original graph\n",
    "    X = graph.get_tensor_by_name(\"Input_X:0\") # assign placeholder variables with input X\n",
    "    y = graph.get_tensor_by_name(\"Input_Label:0\")# assign placeholder variables with input Label\n",
    "    loss = graph.get_tensor_by_name(\"Loss:0\") # assign variables about loss\n",
    "    Y_proba = graph.get_tensor_by_name(\"Softmax_Layer/Softmax:0\") # assign variables about loss\n",
    "    accuracy = graph.get_tensor_by_name(\"Accuracy:0\") # assign variables  about accuracy\n",
    "    \n",
    "    fifth_layer_out = graph.get_tensor_by_name(\"Fully_Connected_Layer_5/Elu:0\").op.outputs[0] # get the output tensors of fifth's layers\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    2. Get the softmax layer which is what we would like to train\n",
    "    \"\"\"\n",
    "    output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"Softmax_Layer\") # get softmax layer by scope name\n",
    "    \n",
    "    \"\"\"\n",
    "    3. Define the optimizer and assign to only update on softmax_layer which defined above\n",
    "    \"\"\"\n",
    "    optimizer = tf.train.AdamOptimizer(0.0017, name=\"Adam_Op\") # create a new optimizer\n",
    "    training_op = optimizer.minimize(loss, var_list=output_layer_vars) # minimize the loss and only update certern variables\n",
    "    var_list_init = tf.variables_initializer([optimizer.get_slot(var, name) for name in optimizer.get_slot_names() for var in output_layer_vars]+list(optimizer._get_beta_accumulators()))# to get the variables name about the softmax layer and \n",
    "\n",
    "    sess.run(var_list_init) # initialize the un-initialized value\n",
    "    \n",
    "    \"\"\"\n",
    "    Get the training output of fifth layer\n",
    "    \"\"\"\n",
    "    fifth_layer_out_cache = sess.run(fifth_layer_out, feed_dict={X:X_train2, y:y_train2}) # feed in the training value and get the fifth layer value out\n",
    "    \n",
    "    \"\"\"\n",
    "    Training Step\n",
    "    \"\"\"\n",
    "    begin_time = time.time() # record the begin training time\n",
    "    for epochs in range(1000): # training on 1000 epochs\n",
    "        _, train_loss = sess.run([training_op, loss], feed_dict={fifth_layer_out:fifth_layer_out_cache, y:y_train2}) # feed with training variables\n",
    "        valid_loss, valid_accuracy = sess.run([loss, accuracy], feed_dict={X:X_valid2, y:y_valid2}) # feed with validation variables\n",
    "        test_loss ,  test_accuracy = sess.run([loss, accuracy], feed_dict={X:X_test2, y:y_test2}) # feed with testing variables\n",
    "        \n",
    "        if valid_accuracy > current_best_accuracy: # if better\n",
    "            current_best_accuracy = valid_accuracy # keep record\n",
    "            save_path = saver.save(sess, \"./Models/TransferLearning/HW3_2/Team26_HW3_2.ckpt\") #keep the best model\n",
    "            no_update_progress = 0\n",
    "        else:                                      # if not better\n",
    "            no_update_progress += 1                # record on no update\n",
    "\n",
    "        if valid_loss < current_best_loss: # if better\n",
    "            current_best_loss = valid_loss # keep record            \n",
    "            \n",
    "        if no_update_progress == no_update_tolerant: break # stop training\n",
    "            \n",
    "                \n",
    "        print(\"{:4d} epochs,   Validation loss:{:.5f},   Best loss:{:.5f},   Accuracy:{:.2f}%/ {:.2f}%\".format(\n",
    "            epochs+1,\n",
    "            valid_loss,\n",
    "            current_best_loss,                                                                                       \n",
    "            valid_accuracy*100, # to show as % we need to *100\n",
    "            test_accuracy*100 # to show as % we need to *100\n",
    "        )) # print the performane for each epochs\n",
    "    finish_itme = time.time() # record the finish time\n",
    "    print(\"\\nTraining Time:{:3f}\".format(finish_itme-begin_time)) # calculate and print training time\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train on 5th Layer + Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Models/yen/mnist_5.ckpt\n",
      "   1 epochs,   Validation loss:1.66993,   Best loss:1.66993,   Accuracy:17.33%/ 20.74%\n",
      "   2 epochs,   Validation loss:1.65561,   Best loss:1.65561,   Accuracy:18.67%/ 22.92%\n",
      "   3 epochs,   Validation loss:1.64016,   Best loss:1.64016,   Accuracy:22.00%/ 24.50%\n",
      "   4 epochs,   Validation loss:1.62364,   Best loss:1.62364,   Accuracy:23.33%/ 26.19%\n",
      "   5 epochs,   Validation loss:1.60615,   Best loss:1.60615,   Accuracy:27.33%/ 28.31%\n",
      "   6 epochs,   Validation loss:1.58786,   Best loss:1.58786,   Accuracy:30.00%/ 30.32%\n",
      "   7 epochs,   Validation loss:1.56895,   Best loss:1.56895,   Accuracy:32.67%/ 32.13%\n",
      "   8 epochs,   Validation loss:1.54965,   Best loss:1.54965,   Accuracy:35.33%/ 34.60%\n",
      "   9 epochs,   Validation loss:1.53029,   Best loss:1.53029,   Accuracy:39.33%/ 36.60%\n",
      "  10 epochs,   Validation loss:1.51136,   Best loss:1.51136,   Accuracy:41.33%/ 38.82%\n",
      "  11 epochs,   Validation loss:1.49336,   Best loss:1.49336,   Accuracy:44.00%/ 40.75%\n",
      "  12 epochs,   Validation loss:1.47674,   Best loss:1.47674,   Accuracy:48.00%/ 42.95%\n",
      "  13 epochs,   Validation loss:1.46172,   Best loss:1.46172,   Accuracy:47.33%/ 44.66%\n",
      "  14 epochs,   Validation loss:1.44826,   Best loss:1.44826,   Accuracy:49.33%/ 46.23%\n",
      "  15 epochs,   Validation loss:1.43612,   Best loss:1.43612,   Accuracy:50.00%/ 47.69%\n",
      "  16 epochs,   Validation loss:1.42493,   Best loss:1.42493,   Accuracy:50.00%/ 49.66%\n",
      "  17 epochs,   Validation loss:1.41431,   Best loss:1.41431,   Accuracy:49.33%/ 51.02%\n",
      "  18 epochs,   Validation loss:1.40386,   Best loss:1.40386,   Accuracy:50.67%/ 52.46%\n",
      "  19 epochs,   Validation loss:1.39324,   Best loss:1.39324,   Accuracy:51.33%/ 53.90%\n",
      "  20 epochs,   Validation loss:1.38214,   Best loss:1.38214,   Accuracy:52.00%/ 55.26%\n",
      "  21 epochs,   Validation loss:1.37040,   Best loss:1.37040,   Accuracy:53.33%/ 56.78%\n",
      "  22 epochs,   Validation loss:1.35804,   Best loss:1.35804,   Accuracy:56.00%/ 58.32%\n",
      "  23 epochs,   Validation loss:1.34522,   Best loss:1.34522,   Accuracy:56.67%/ 60.30%\n",
      "  24 epochs,   Validation loss:1.33222,   Best loss:1.33222,   Accuracy:56.67%/ 62.11%\n",
      "  25 epochs,   Validation loss:1.31933,   Best loss:1.31933,   Accuracy:58.67%/ 63.71%\n",
      "  26 epochs,   Validation loss:1.30680,   Best loss:1.30680,   Accuracy:60.00%/ 64.76%\n",
      "  27 epochs,   Validation loss:1.29477,   Best loss:1.29477,   Accuracy:60.67%/ 66.28%\n",
      "  28 epochs,   Validation loss:1.28333,   Best loss:1.28333,   Accuracy:62.00%/ 66.94%\n",
      "  29 epochs,   Validation loss:1.27245,   Best loss:1.27245,   Accuracy:63.33%/ 67.87%\n",
      "  30 epochs,   Validation loss:1.26202,   Best loss:1.26202,   Accuracy:64.67%/ 68.81%\n",
      "  31 epochs,   Validation loss:1.25194,   Best loss:1.25194,   Accuracy:66.67%/ 69.47%\n",
      "  32 epochs,   Validation loss:1.24208,   Best loss:1.24208,   Accuracy:68.00%/ 70.19%\n",
      "  33 epochs,   Validation loss:1.23238,   Best loss:1.23238,   Accuracy:69.33%/ 71.12%\n",
      "  34 epochs,   Validation loss:1.22282,   Best loss:1.22282,   Accuracy:70.00%/ 72.02%\n",
      "  35 epochs,   Validation loss:1.21344,   Best loss:1.21344,   Accuracy:70.00%/ 72.54%\n",
      "  36 epochs,   Validation loss:1.20440,   Best loss:1.20440,   Accuracy:70.00%/ 73.11%\n",
      "  37 epochs,   Validation loss:1.19587,   Best loss:1.19587,   Accuracy:72.00%/ 73.85%\n",
      "  38 epochs,   Validation loss:1.18804,   Best loss:1.18804,   Accuracy:73.33%/ 74.49%\n",
      "  39 epochs,   Validation loss:1.18101,   Best loss:1.18101,   Accuracy:72.67%/ 74.94%\n",
      "  40 epochs,   Validation loss:1.17479,   Best loss:1.17479,   Accuracy:76.00%/ 75.56%\n",
      "  41 epochs,   Validation loss:1.16935,   Best loss:1.16935,   Accuracy:76.00%/ 75.99%\n",
      "  42 epochs,   Validation loss:1.16458,   Best loss:1.16458,   Accuracy:75.33%/ 76.22%\n",
      "  43 epochs,   Validation loss:1.16042,   Best loss:1.16042,   Accuracy:75.33%/ 76.57%\n",
      "  44 epochs,   Validation loss:1.15675,   Best loss:1.15675,   Accuracy:76.67%/ 76.88%\n",
      "  45 epochs,   Validation loss:1.15349,   Best loss:1.15349,   Accuracy:76.67%/ 77.31%\n",
      "  46 epochs,   Validation loss:1.15057,   Best loss:1.15057,   Accuracy:76.67%/ 77.68%\n",
      "  47 epochs,   Validation loss:1.14792,   Best loss:1.14792,   Accuracy:76.67%/ 77.93%\n",
      "  48 epochs,   Validation loss:1.14547,   Best loss:1.14547,   Accuracy:77.33%/ 78.17%\n",
      "  49 epochs,   Validation loss:1.14319,   Best loss:1.14319,   Accuracy:77.33%/ 78.26%\n",
      "  50 epochs,   Validation loss:1.14102,   Best loss:1.14102,   Accuracy:77.33%/ 78.54%\n",
      "  51 epochs,   Validation loss:1.13894,   Best loss:1.13894,   Accuracy:77.33%/ 78.85%\n",
      "  52 epochs,   Validation loss:1.13692,   Best loss:1.13692,   Accuracy:77.33%/ 79.18%\n",
      "  53 epochs,   Validation loss:1.13494,   Best loss:1.13494,   Accuracy:78.00%/ 79.33%\n",
      "  54 epochs,   Validation loss:1.13298,   Best loss:1.13298,   Accuracy:77.33%/ 79.43%\n",
      "  55 epochs,   Validation loss:1.13103,   Best loss:1.13103,   Accuracy:77.33%/ 79.43%\n",
      "  56 epochs,   Validation loss:1.12910,   Best loss:1.12910,   Accuracy:78.00%/ 79.59%\n",
      "  57 epochs,   Validation loss:1.12716,   Best loss:1.12716,   Accuracy:78.00%/ 79.76%\n",
      "  58 epochs,   Validation loss:1.12523,   Best loss:1.12523,   Accuracy:78.00%/ 79.88%\n",
      "  59 epochs,   Validation loss:1.12330,   Best loss:1.12330,   Accuracy:79.33%/ 80.00%\n",
      "  60 epochs,   Validation loss:1.12139,   Best loss:1.12139,   Accuracy:79.33%/ 80.11%\n",
      "  61 epochs,   Validation loss:1.11950,   Best loss:1.11950,   Accuracy:79.33%/ 80.31%\n",
      "  62 epochs,   Validation loss:1.11765,   Best loss:1.11765,   Accuracy:79.33%/ 80.52%\n",
      "  63 epochs,   Validation loss:1.11583,   Best loss:1.11583,   Accuracy:80.00%/ 80.64%\n",
      "  64 epochs,   Validation loss:1.11407,   Best loss:1.11407,   Accuracy:80.00%/ 80.81%\n",
      "  65 epochs,   Validation loss:1.11236,   Best loss:1.11236,   Accuracy:80.00%/ 80.99%\n",
      "  66 epochs,   Validation loss:1.11072,   Best loss:1.11072,   Accuracy:80.00%/ 81.14%\n",
      "  67 epochs,   Validation loss:1.10915,   Best loss:1.10915,   Accuracy:80.00%/ 81.22%\n",
      "  68 epochs,   Validation loss:1.10765,   Best loss:1.10765,   Accuracy:80.67%/ 81.30%\n",
      "  69 epochs,   Validation loss:1.10623,   Best loss:1.10623,   Accuracy:81.33%/ 81.38%\n",
      "  70 epochs,   Validation loss:1.10488,   Best loss:1.10488,   Accuracy:81.33%/ 81.59%\n",
      "  71 epochs,   Validation loss:1.10361,   Best loss:1.10361,   Accuracy:81.33%/ 81.61%\n",
      "  72 epochs,   Validation loss:1.10241,   Best loss:1.10241,   Accuracy:81.33%/ 81.61%\n",
      "  73 epochs,   Validation loss:1.10129,   Best loss:1.10129,   Accuracy:82.00%/ 81.77%\n",
      "  74 epochs,   Validation loss:1.10022,   Best loss:1.10022,   Accuracy:83.33%/ 81.81%\n",
      "  75 epochs,   Validation loss:1.09922,   Best loss:1.09922,   Accuracy:83.33%/ 81.81%\n",
      "  76 epochs,   Validation loss:1.09827,   Best loss:1.09827,   Accuracy:83.33%/ 81.84%\n",
      "  77 epochs,   Validation loss:1.09737,   Best loss:1.09737,   Accuracy:83.33%/ 81.94%\n",
      "  78 epochs,   Validation loss:1.09651,   Best loss:1.09651,   Accuracy:83.33%/ 81.98%\n",
      "  79 epochs,   Validation loss:1.09570,   Best loss:1.09570,   Accuracy:83.33%/ 82.04%\n",
      "  80 epochs,   Validation loss:1.09492,   Best loss:1.09492,   Accuracy:83.33%/ 82.08%\n",
      "  81 epochs,   Validation loss:1.09417,   Best loss:1.09417,   Accuracy:83.33%/ 82.21%\n",
      "  82 epochs,   Validation loss:1.09344,   Best loss:1.09344,   Accuracy:83.33%/ 82.27%\n",
      "  83 epochs,   Validation loss:1.09273,   Best loss:1.09273,   Accuracy:84.00%/ 82.43%\n",
      "  84 epochs,   Validation loss:1.09204,   Best loss:1.09204,   Accuracy:84.00%/ 82.41%\n",
      "  85 epochs,   Validation loss:1.09136,   Best loss:1.09136,   Accuracy:84.67%/ 82.45%\n",
      "  86 epochs,   Validation loss:1.09069,   Best loss:1.09069,   Accuracy:84.67%/ 82.49%\n",
      "  87 epochs,   Validation loss:1.09003,   Best loss:1.09003,   Accuracy:84.67%/ 82.53%\n",
      "  88 epochs,   Validation loss:1.08937,   Best loss:1.08937,   Accuracy:84.67%/ 82.56%\n",
      "  89 epochs,   Validation loss:1.08870,   Best loss:1.08870,   Accuracy:84.67%/ 82.53%\n",
      "  90 epochs,   Validation loss:1.08804,   Best loss:1.08804,   Accuracy:84.67%/ 82.53%\n",
      "  91 epochs,   Validation loss:1.08738,   Best loss:1.08738,   Accuracy:84.67%/ 82.58%\n",
      "  92 epochs,   Validation loss:1.08672,   Best loss:1.08672,   Accuracy:84.67%/ 82.58%\n",
      "  93 epochs,   Validation loss:1.08606,   Best loss:1.08606,   Accuracy:84.67%/ 82.64%\n",
      "  94 epochs,   Validation loss:1.08539,   Best loss:1.08539,   Accuracy:84.67%/ 82.68%\n",
      "  95 epochs,   Validation loss:1.08473,   Best loss:1.08473,   Accuracy:84.67%/ 82.72%\n",
      "  96 epochs,   Validation loss:1.08407,   Best loss:1.08407,   Accuracy:84.67%/ 82.68%\n",
      "  97 epochs,   Validation loss:1.08341,   Best loss:1.08341,   Accuracy:84.67%/ 82.72%\n",
      "  98 epochs,   Validation loss:1.08276,   Best loss:1.08276,   Accuracy:84.67%/ 82.76%\n",
      "  99 epochs,   Validation loss:1.08211,   Best loss:1.08211,   Accuracy:84.67%/ 82.76%\n",
      " 100 epochs,   Validation loss:1.08147,   Best loss:1.08147,   Accuracy:84.67%/ 82.76%\n",
      " 101 epochs,   Validation loss:1.08083,   Best loss:1.08083,   Accuracy:84.67%/ 82.82%\n",
      " 102 epochs,   Validation loss:1.08021,   Best loss:1.08021,   Accuracy:84.67%/ 82.80%\n",
      " 103 epochs,   Validation loss:1.07960,   Best loss:1.07960,   Accuracy:84.67%/ 82.78%\n",
      " 104 epochs,   Validation loss:1.07900,   Best loss:1.07900,   Accuracy:84.67%/ 82.74%\n",
      "\n",
      "Training Time:81.550396\n"
     ]
    }
   ],
   "source": [
    "reset_graph() # clean the graph\n",
    "\n",
    "no_update_tolerant = 20 # set the criteria that if the model didn't get better for how many epochs\n",
    "\n",
    "no_update_progress = 0 # the variables to record for the not better epochs\n",
    "current_best_accuracy = 0.0 # variables to record the best valid accuracy\n",
    "current_best_loss = 10.0 # variables to record the best valid loss\n",
    "\n",
    "with tf.Session() as sess: # start the tensorflow nn session\n",
    "    restore_saver = tf.train.import_meta_graph(\"./Models/yen/mnist_5.ckpt.meta\") # load meta graph\n",
    "    restore_saver.restore(sess, tf.train.latest_checkpoint('./Models/yen/')) # restore weights\n",
    "\n",
    "    saver = tf.train.Saver() # to store the model\n",
    "    \"\"\"\n",
    "    Graph Define Step\n",
    "    \n",
    "    1. Restore the variable about the component in graph which help to retrieve and assign value\n",
    "    \"\"\"\n",
    "    graph = tf.get_default_graph() # get original graph\n",
    "    X = graph.get_tensor_by_name(\"Input_X:0\") # assign placeholder variables with input X\n",
    "    y = graph.get_tensor_by_name(\"Input_Label:0\")# assign placeholder variables with input Label\n",
    "    \n",
    "    fourth_layer_out = graph.get_tensor_by_name(\"Fully_Connected_Layer_4/Elu:0\").op.outputs[0] # get the output of fourth layer\n",
    "#     print(fourth_layer_out)\n",
    "    \n",
    "    \"\"\"\n",
    "    2. Get the training output of fourth layer\n",
    "    \"\"\"\n",
    "    fourth_layer_out_cache = sess.run(fourth_layer_out, feed_dict={X:X_train2, y:y_train2}) # get the output of fourth layer\n",
    "#     print(fourth_layer_out_cache.shape)\n",
    "    temp = set(tf.global_variables()) # record the the variables now, which will be used after new variables are created\n",
    "    \"\"\"\n",
    "    3.Create new softmax layer and connect old fourth layer, connect to softmax layer\n",
    "    \"\"\"\n",
    "    y_ = tf.layers.dense(inputs=fourth_layer_out, \n",
    "                             units=5, \n",
    "                             activation=tf.nn.softmax, #softmax\n",
    "                             kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),\n",
    "                             name = \"New_Softmax_Layer\"\n",
    "                            )  # Create the new softmax layer using dense\n",
    "\n",
    "    \"\"\"\n",
    "    4. Get the softmax layer which is what we would like to train\n",
    "    \"\"\"\n",
    "    output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"New_Softmax_Layer\") # get softmax layer by scope name\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    5. Define loss, optimizer and assign to only update on softmax_layer which defined above\n",
    "    \"\"\"   \n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=y_, name=\"New_Cross_Entropy\"), name=\"New_Loss\") # Refine Loss Function\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(0.0017, name=\"Adam_Op\") # new adam optimizer\n",
    "    training_op = optimizer.minimize(loss, var_list=output_layer_vars) # minimize the loss and only update certern variables\n",
    "    \n",
    "    \"\"\"\n",
    "    6. Define new evaluation metrics\n",
    "    \"\"\"\n",
    "    predicted_class = tf.argmax(y_, 1, output_type=tf.int32) # Define Accuracy\n",
    "    correct_predict = tf.equal(y, predicted_class) # [True, False ..., True]\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32)) # [True, False ..., True] --> [1,0,...,1]\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    7. Initialize all the variables\n",
    "    \"\"\"\n",
    "    var_list_init = tf.variables_initializer(set(tf.global_variables())-temp) # to get new variables that we created afterward\n",
    "    sess.run(var_list_init) # init the variable about fourth + softmax layer + adam optimizer\n",
    "   \n",
    "    \n",
    "    \"\"\"\n",
    "    Training Step\n",
    "    \"\"\"\n",
    "    begin_time = time.time()  # record the begin training time\n",
    "    for epochs in range(1000): # training on 1000 epochs\n",
    "        _, train_loss = sess.run([training_op, loss], feed_dict={fourth_layer_out:fourth_layer_out_cache, y:y_train2}) # feed with training variables\n",
    "        valid_loss, valid_accuracy = sess.run([loss, accuracy], feed_dict={X:X_valid2, y:y_valid2}) # feed with validation variables\n",
    "        test_loss ,  test_accuracy = sess.run([loss, accuracy], feed_dict={X:X_test2, y:y_test2}) # feed with testing variables\n",
    "        \n",
    "        if valid_accuracy > current_best_accuracy: # if better\n",
    "            current_best_accuracy = valid_accuracy # keep record\n",
    "            save_path = saver.save(sess, \"./Models/TransferLearning/HW3_3/Team26_HW3_3.ckpt\") #keep the best model\n",
    "            no_update_progress = 0\n",
    "        else:                                      # if not better\n",
    "            no_update_progress += 1                # record on no update\n",
    "\n",
    "        if valid_loss < current_best_loss: # if better\n",
    "            current_best_loss = valid_loss # keep record            \n",
    "            \n",
    "        if no_update_progress == no_update_tolerant: break # stop training\n",
    "            \n",
    "                \n",
    "        print(\"{:4d} epochs,   Validation loss:{:.5f},   Best loss:{:.5f},   Accuracy:{:.2f}%/ {:.2f}%\".format(\n",
    "            epochs+1,\n",
    "            valid_loss,\n",
    "            current_best_loss,                                                                                       \n",
    "            valid_accuracy*100,\n",
    "            test_accuracy*100\n",
    "        )) # print the performane for each epochs\n",
    "    finish_itme = time.time() # record the finish time\n",
    "    print(\"\\nTraining Time:{:3f}\".format(finish_itme-begin_time)) # calculate and print training time\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Only Frozen 3th & 4th Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Models/yen/mnist_5.ckpt\n",
      "   1 epochs,   Validation loss:1.45242,   Best loss:1.45242,   Accuracy:56.67%/ 53.96%\n",
      "   2 epochs,   Validation loss:1.30615,   Best loss:1.30615,   Accuracy:64.00%/ 62.85%\n",
      "   3 epochs,   Validation loss:1.22268,   Best loss:1.22268,   Accuracy:72.67%/ 72.08%\n",
      "   4 epochs,   Validation loss:1.15723,   Best loss:1.15723,   Accuracy:77.33%/ 79.47%\n",
      "   5 epochs,   Validation loss:1.09979,   Best loss:1.09979,   Accuracy:86.00%/ 82.35%\n",
      "   6 epochs,   Validation loss:1.07310,   Best loss:1.07310,   Accuracy:86.67%/ 83.32%\n",
      "   7 epochs,   Validation loss:1.05733,   Best loss:1.05733,   Accuracy:84.67%/ 86.81%\n",
      "   8 epochs,   Validation loss:1.05152,   Best loss:1.05152,   Accuracy:86.67%/ 87.60%\n",
      "   9 epochs,   Validation loss:1.03713,   Best loss:1.03713,   Accuracy:87.33%/ 88.44%\n",
      "  10 epochs,   Validation loss:1.02537,   Best loss:1.02537,   Accuracy:88.67%/ 88.87%\n",
      "  11 epochs,   Validation loss:1.02439,   Best loss:1.02439,   Accuracy:88.00%/ 89.28%\n",
      "  12 epochs,   Validation loss:1.02587,   Best loss:1.02439,   Accuracy:88.67%/ 90.08%\n",
      "  13 epochs,   Validation loss:1.02747,   Best loss:1.02439,   Accuracy:88.00%/ 90.27%\n",
      "  14 epochs,   Validation loss:1.03061,   Best loss:1.02439,   Accuracy:88.00%/ 90.27%\n",
      "  15 epochs,   Validation loss:1.03290,   Best loss:1.02439,   Accuracy:85.33%/ 90.23%\n",
      "  16 epochs,   Validation loss:1.03053,   Best loss:1.02439,   Accuracy:86.00%/ 90.35%\n",
      "  17 epochs,   Validation loss:1.02263,   Best loss:1.02263,   Accuracy:88.67%/ 90.85%\n",
      "  18 epochs,   Validation loss:1.01208,   Best loss:1.01208,   Accuracy:89.33%/ 90.72%\n",
      "  19 epochs,   Validation loss:1.00437,   Best loss:1.00437,   Accuracy:89.33%/ 90.50%\n",
      "  20 epochs,   Validation loss:1.00148,   Best loss:1.00148,   Accuracy:90.00%/ 90.48%\n",
      "  21 epochs,   Validation loss:1.00343,   Best loss:1.00148,   Accuracy:88.67%/ 90.35%\n",
      "  22 epochs,   Validation loss:1.00708,   Best loss:1.00148,   Accuracy:88.67%/ 90.27%\n",
      "  23 epochs,   Validation loss:1.00920,   Best loss:1.00148,   Accuracy:88.67%/ 90.31%\n",
      "  24 epochs,   Validation loss:1.00837,   Best loss:1.00148,   Accuracy:88.67%/ 90.45%\n",
      "  25 epochs,   Validation loss:1.00498,   Best loss:1.00148,   Accuracy:89.33%/ 90.76%\n",
      "  26 epochs,   Validation loss:1.00099,   Best loss:1.00099,   Accuracy:90.67%/ 90.91%\n",
      "  27 epochs,   Validation loss:0.99977,   Best loss:0.99977,   Accuracy:90.67%/ 90.95%\n",
      "  28 epochs,   Validation loss:1.00517,   Best loss:0.99977,   Accuracy:90.00%/ 90.85%\n",
      "  29 epochs,   Validation loss:1.00798,   Best loss:0.99977,   Accuracy:90.00%/ 90.76%\n",
      "  30 epochs,   Validation loss:1.00465,   Best loss:0.99977,   Accuracy:89.33%/ 90.70%\n",
      "  31 epochs,   Validation loss:0.99808,   Best loss:0.99808,   Accuracy:90.67%/ 90.82%\n",
      "  32 epochs,   Validation loss:0.99333,   Best loss:0.99333,   Accuracy:92.00%/ 90.87%\n",
      "  33 epochs,   Validation loss:0.99189,   Best loss:0.99189,   Accuracy:91.33%/ 90.66%\n",
      "  34 epochs,   Validation loss:0.99197,   Best loss:0.99189,   Accuracy:90.67%/ 90.37%\n",
      "  35 epochs,   Validation loss:0.99266,   Best loss:0.99189,   Accuracy:90.67%/ 90.37%\n",
      "  36 epochs,   Validation loss:0.99375,   Best loss:0.99189,   Accuracy:90.00%/ 90.50%\n",
      "  37 epochs,   Validation loss:0.99525,   Best loss:0.99189,   Accuracy:90.00%/ 90.54%\n",
      "  38 epochs,   Validation loss:0.99727,   Best loss:0.99189,   Accuracy:90.00%/ 90.52%\n",
      "  39 epochs,   Validation loss:0.99978,   Best loss:0.99189,   Accuracy:89.33%/ 90.60%\n",
      "  40 epochs,   Validation loss:1.00234,   Best loss:0.99189,   Accuracy:88.00%/ 90.68%\n",
      "  41 epochs,   Validation loss:1.00435,   Best loss:0.99189,   Accuracy:89.33%/ 90.66%\n",
      "  42 epochs,   Validation loss:1.00561,   Best loss:0.99189,   Accuracy:90.67%/ 90.62%\n",
      "  43 epochs,   Validation loss:1.00612,   Best loss:0.99189,   Accuracy:90.00%/ 90.68%\n",
      "  44 epochs,   Validation loss:1.00594,   Best loss:0.99189,   Accuracy:90.00%/ 90.60%\n",
      "  45 epochs,   Validation loss:1.00515,   Best loss:0.99189,   Accuracy:90.00%/ 90.72%\n",
      "  46 epochs,   Validation loss:1.00395,   Best loss:0.99189,   Accuracy:90.67%/ 90.85%\n",
      "  47 epochs,   Validation loss:1.00255,   Best loss:0.99189,   Accuracy:90.67%/ 90.74%\n",
      "  48 epochs,   Validation loss:1.00125,   Best loss:0.99189,   Accuracy:90.67%/ 90.74%\n",
      "  49 epochs,   Validation loss:1.00036,   Best loss:0.99189,   Accuracy:90.00%/ 90.70%\n",
      "  50 epochs,   Validation loss:1.00029,   Best loss:0.99189,   Accuracy:90.00%/ 90.68%\n",
      "  51 epochs,   Validation loss:1.00086,   Best loss:0.99189,   Accuracy:89.33%/ 90.74%\n",
      "\n",
      "Training Time:21.426986\n"
     ]
    }
   ],
   "source": [
    "reset_graph() # clean the graph\n",
    "\n",
    "no_update_tolerant = 20 # set the criteria that if the model didn't get better for how many epochs\n",
    "\n",
    "no_update_progress = 0 # the variables to record for the not better epochs\n",
    "current_best_accuracy = 0.0 # variables to record the best valid accuracy\n",
    "current_best_loss = 10.0 # variables to record the best valid loss\n",
    "\n",
    "with tf.Session() as sess: # start the tensorflow nn session\n",
    "    restore_saver = tf.train.import_meta_graph(\"./Models/yen/mnist_5.ckpt.meta\") # load meta graph\n",
    "    restore_saver.restore(sess, tf.train.latest_checkpoint('./Models/yen/')) # restore weights\n",
    "\n",
    "    saver = tf.train.Saver() # to store the model\n",
    "    \"\"\"\n",
    "    Graph Define Step\n",
    "    \n",
    "    1. Restore the variable about the component in graph which help to retrieve and assign value\n",
    "    \"\"\"\n",
    "    graph = tf.get_default_graph() # get original graph\n",
    "    X = graph.get_tensor_by_name(\"Input_X:0\") # assign placeholder variables with input X\n",
    "    y = graph.get_tensor_by_name(\"Input_Label:0\")# assign placeholder variables with input Label\n",
    "    \n",
    "    fourth_layer_out = graph.get_tensor_by_name(\"Fully_Connected_Layer_4/Elu:0\").op.outputs[0]\n",
    "    \"\"\"\n",
    "    2.Create new softmax layer and connect old fourth layer, connect to softmax layer\n",
    "    \"\"\"\n",
    "    y_ = tf.layers.dense(inputs=fourth_layer_out, \n",
    "                             units=5, \n",
    "                             activation=tf.nn.softmax, #softmax\n",
    "                             kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),\n",
    "                             name = \"New_Softmax_Layer\"\n",
    "                            )  # Layer using dense\n",
    "\n",
    "    \"\"\"\n",
    "    3. Get the 1th, 2th and softmax layer which is what we would like to train\n",
    "    \"\"\"\n",
    "    output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"Fully_Connected_Layer_1\") # get softmax layer by scope name\n",
    "    output_layer_vars += tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"Fully_Connected_Layer_2\") # get softmax layer by scope name\n",
    "    output_layer_vars += tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"New_Softmax_Layer\") # get softmax layer by scope name\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    4. Define loss, optimizer and assign to only update on softmax_layer which defined above\n",
    "    \"\"\"   \n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=y_, name=\"New_Cross_Entropy\"), name=\"New_Loss\") # Refine Loss Function\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(0.0017, name=\"Adam_Op\") # create a new optimizer\n",
    "    training_op = optimizer.minimize(loss) # minimize the loss and only update certern variables\n",
    "    \n",
    "    \"\"\"\n",
    "    5. Define new evaluation metrics\n",
    "    \"\"\"\n",
    "    predicted_class = tf.argmax(y_, 1, output_type=tf.int32) # Define Accuracy\n",
    "    correct_predict = tf.equal(y, predicted_class) # [True, False ..., True]\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32)) # [True, False ..., True] --> [1,0,...,1]\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    6. Initialize all the variables\n",
    "    \"\"\"\n",
    "    var_list_init = tf.variables_initializer(set(tf.global_variables())-temp)\n",
    "    sess.run(var_list_init) # init the variable about fourth + softmax layer + adam optimizer\n",
    "   \n",
    "    \n",
    "    \"\"\"\n",
    "    Training Step\n",
    "    \"\"\"\n",
    "    begin_time = time.time() # record the begin training time\n",
    "    for epochs in range(1000): # training on 1000 epochs\n",
    "        _, train_loss = sess.run([training_op, loss], feed_dict={X:X_train2, y:y_train2}) # feed with training variables\n",
    "        valid_loss, valid_accuracy = sess.run([loss, accuracy], feed_dict={X:X_valid2, y:y_valid2}) # feed with validation variables\n",
    "        test_loss ,  test_accuracy = sess.run([loss, accuracy], feed_dict={X:X_test2, y:y_test2}) # feed with testing variables\n",
    "        \n",
    "        if valid_accuracy > current_best_accuracy: # if better\n",
    "            current_best_accuracy = valid_accuracy # keep record\n",
    "            save_path = saver.save(sess, \"./Models/TransferLearning/HW3_4/Team26_HW3_4.ckpt\") #keep the best model\n",
    "            no_update_progress = 0\n",
    "        else:                                      # if not better\n",
    "            no_update_progress += 1                # record on no update\n",
    "\n",
    "        if valid_loss < current_best_loss: # if better\n",
    "            current_best_loss = valid_loss # keep record            \n",
    "            \n",
    "        if no_update_progress == no_update_tolerant: break # stop training\n",
    "            \n",
    "                \n",
    "        print(\"{:4d} epochs,   Validation loss:{:.5f},   Best loss:{:.5f},   Accuracy:{:.2f}%/ {:.2f}%\".format(\n",
    "            epochs+1,\n",
    "            valid_loss,\n",
    "            current_best_loss,                                                                                       \n",
    "            valid_accuracy*100,\n",
    "            test_accuracy*100\n",
    "        )) # print the performane for each epochs\n",
    "    finish_itme = time.time() # record the finish time\n",
    "    print(\"\\nTraining Time:{:3f}\".format(finish_itme-begin_time)) # calculate and print training time\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
