{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load data: digits 5 to 9, but still label with 0 to 4, \n",
    "# because TensorFlow expects label's integers from 0 to n_classes-1.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train2_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train2_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "X_valid2_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid2_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "X_test2 = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test2 = mnist.test.labels[mnist.test.labels >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we want to keep only 100 instances per class in the training set \n",
    "# and let's keep only 30 instances per class in the validation set\n",
    "# tesing set is already loaded above\n",
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)\n",
    "\n",
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Train Softmax Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Models/yen/mnist_5.ckpt\n",
      "Fully_Connected_Layer_1/kernel:0 with value [[ 0.03314166 -0.09055354 -0.08280303 ...,  0.04810002 -0.07048665\n",
      "   0.03521701]\n",
      " [ 0.06279289 -0.02778894  0.01664921 ..., -0.01901775  0.06809777\n",
      "   0.04352102]\n",
      " [-0.05096035  0.03554505 -0.05947971 ..., -0.10324872  0.06255207\n",
      "   0.00371845]\n",
      " ..., \n",
      " [ 0.01253158  0.10347325  0.03930723 ..., -0.00621642 -0.05332955\n",
      "   0.08313946]\n",
      " [-0.02647174  0.06996583  0.04140012 ...,  0.00750363 -0.09673171\n",
      "  -0.00074043]\n",
      " [ 0.05517064  0.02086869  0.01615661 ...,  0.08531171  0.06016324\n",
      "   0.06593282]]\n",
      "Fully_Connected_Layer_1/bias:0 with value [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "Fully_Connected_Layer_2/kernel:0 with value [[-0.01735752  0.12698385 -0.02251823 ..., -0.08227649 -0.08361708\n",
      "   0.12524855]\n",
      " [ 0.19859043  0.01664343 -0.00808965 ...,  0.12657219 -0.08235261\n",
      "  -0.05385672]\n",
      " [ 0.11842413 -0.05042088  0.00332435 ...,  0.15614758 -0.27094701\n",
      "  -0.00696838]\n",
      " ..., \n",
      " [-0.00941979 -0.0482985   0.10143601 ...,  0.08856079  0.26421559\n",
      "  -0.07990757]\n",
      " [ 0.17439985 -0.00369467  0.13807561 ...,  0.04613412 -0.07338098\n",
      "  -0.00827259]\n",
      " [-0.08538907  0.07220204  0.2093915  ..., -0.21402493  0.12099838\n",
      "  -0.00564923]]\n",
      "Fully_Connected_Layer_2/bias:0 with value [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "Fully_Connected_Layer_3/kernel:0 with value [[-0.12384547 -0.17741331 -0.13974901 ..., -0.22103618 -0.01731236\n",
      "   0.10687768]\n",
      " [-0.0018799  -0.21839181  0.16438161 ..., -0.0204991  -0.09439672\n",
      "   0.23917192]\n",
      " [ 0.05525109 -0.04978212 -0.09592032 ..., -0.06943489 -0.04819438\n",
      "  -0.02644189]\n",
      " ..., \n",
      " [ 0.05417781 -0.09972005  0.06557674 ...,  0.0413112   0.15128194\n",
      "  -0.14687745]\n",
      " [-0.17452897 -0.07226198 -0.17491755 ..., -0.05628029  0.17689818\n",
      "   0.07930223]\n",
      " [-0.16728307  0.0393256  -0.14045069 ..., -0.00207269 -0.05558012\n",
      "   0.05443545]]\n",
      "Fully_Connected_Layer_3/bias:0 with value [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "Fully_Connected_Layer_4/kernel:0 with value [[-0.25788695 -0.03962068  0.1439952  ..., -0.01184258  0.03254261\n",
      "  -0.02307259]\n",
      " [ 0.09473923 -0.06608172 -0.16313119 ..., -0.05424254  0.15997711\n",
      "  -0.0605418 ]\n",
      " [-0.17492718 -0.07203924  0.12564328 ..., -0.05615833 -0.2290218\n",
      "   0.17297481]\n",
      " ..., \n",
      " [ 0.17404278 -0.05369671 -0.04369495 ..., -0.08731454  0.05617743\n",
      "  -0.0446208 ]\n",
      " [-0.00704536 -0.1212432   0.27324983 ...,  0.18995297  0.14113894\n",
      "  -0.1511317 ]\n",
      " [ 0.04638887 -0.03345469 -0.05346066 ...,  0.21861337 -0.09845864\n",
      "  -0.01619568]]\n",
      "Fully_Connected_Layer_4/bias:0 with value [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "Fully_Connected_Layer_5/kernel:0 with value [[-0.05260144 -0.03542071  0.07877646 ..., -0.14167482 -0.01056051\n",
      "  -0.10185055]\n",
      " [-0.18563344 -0.02711603 -0.16600464 ..., -0.06297085  0.1037299\n",
      "   0.11783128]\n",
      " [ 0.08474639  0.10159537  0.08052302 ..., -0.04580641 -0.07464491\n",
      "  -0.07116183]\n",
      " ..., \n",
      " [-0.02807751  0.1195838  -0.08853205 ..., -0.06135331  0.03226716\n",
      "  -0.25101963]\n",
      " [ 0.18847765  0.09018914 -0.12222814 ...,  0.11789048  0.13302875\n",
      "  -0.22103442]\n",
      " [-0.17011316  0.04901059 -0.00740054 ..., -0.26499534  0.0834461\n",
      "   0.03557335]]\n",
      "Fully_Connected_Layer_5/bias:0 with value [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "Softmax_Layer/kernel:0 with value [[-0.13311061 -0.09957232 -0.14929217 -0.10819482  0.10612718]\n",
      " [-0.23372675  0.03805228  0.0372492   0.03301213 -0.11060204]\n",
      " [ 0.11568984  0.10715763 -0.05876458  0.2432225  -0.19735081]\n",
      " [-0.21879168 -0.00137182  0.25821066 -0.03878487  0.15799277]\n",
      " [-0.10369977 -0.03791933 -0.13286303 -0.04538935 -0.04074268]\n",
      " [-0.11660679  0.24282299 -0.14684007  0.19827989  0.17365555]\n",
      " [ 0.10260972  0.12208026  0.08781124  0.14740711 -0.12343232]\n",
      " [-0.13674012  0.08236381  0.0399996  -0.06699374  0.14204445]\n",
      " [ 0.10380634  0.00169181 -0.00217689  0.0981139   0.09676559]\n",
      " [-0.0461962   0.13324428  0.06401267 -0.15151924 -0.2065752 ]\n",
      " [-0.03534992  0.05136384 -0.09277522  0.18342209 -0.1531003 ]\n",
      " [-0.03773353  0.15356509 -0.03423344 -0.18120211  0.14404806]\n",
      " [ 0.24493971 -0.19483984  0.06194674  0.20977353  0.04995678]\n",
      " [ 0.13684763  0.11562138  0.12372887  0.13064118 -0.02412297]\n",
      " [ 0.05846409  0.01028726  0.14675893  0.22819886  0.0454743 ]\n",
      " [-0.07651924  0.04147702 -0.18105559  0.02821477 -0.17548418]\n",
      " [-0.15687552  0.105331    0.15480308 -0.25536272  0.11793092]\n",
      " [-0.07182031  0.0430886  -0.07798729 -0.00339888  0.0252035 ]\n",
      " [-0.26776537 -0.08147633 -0.01203392  0.04586415 -0.08723523]\n",
      " [ 0.15876834  0.25605047 -0.04123075  0.05920306  0.14519531]\n",
      " [-0.21249202  0.09460706  0.17093229  0.01823769 -0.03948131]\n",
      " [ 0.10106214  0.08639728 -0.27837142 -0.08421738  0.0090731 ]\n",
      " [-0.06117551  0.07951503 -0.18062252 -0.03599656  0.24485534]\n",
      " [ 0.10099079 -0.02166122 -0.07002381 -0.18914309 -0.10088188]\n",
      " [ 0.06901786  0.08585585 -0.2094546   0.0125784  -0.26848468]\n",
      " [ 0.20194268  0.02369044 -0.07098984  0.00488833  0.06541982]\n",
      " [-0.02555792 -0.09928904 -0.09014352 -0.06019851 -0.13738979]\n",
      " [-0.14862719  0.09618782  0.06499021  0.15289611  0.1795627 ]\n",
      " [-0.24272801 -0.0680716  -0.12372658 -0.03189712 -0.17409995]\n",
      " [-0.13915581 -0.04885004 -0.02977312 -0.22480212  0.06046963]\n",
      " [-0.0256477   0.20669708  0.14088291  0.04998536 -0.15663038]\n",
      " [ 0.07459802  0.07576574 -0.07730339 -0.27976009  0.09881819]\n",
      " [ 0.03702413  0.10196284 -0.03540064  0.11134732  0.1533169 ]\n",
      " [-0.04021139 -0.05904894  0.07218365  0.2526435   0.22046512]\n",
      " [ 0.0248605  -0.18916793 -0.0341107  -0.0271554   0.1145893 ]\n",
      " [-0.23156191 -0.02755483  0.00222755 -0.21362282 -0.07095928]\n",
      " [-0.20380512 -0.05002158  0.21251497 -0.06006043 -0.01058291]\n",
      " [-0.146392   -0.09890226  0.02209303  0.04899124 -0.01028797]\n",
      " [ 0.28273857  0.17323846  0.08598977  0.1159111  -0.01336641]\n",
      " [ 0.03775035 -0.14086126  0.1976348   0.19638024 -0.07335071]\n",
      " [ 0.26917526 -0.11613692  0.12366081  0.08772843  0.05355485]\n",
      " [ 0.02521185  0.00352478 -0.09400428 -0.05886153 -0.18465576]\n",
      " [ 0.24560863  0.26152343 -0.15092818  0.18490587 -0.05758004]\n",
      " [-0.14762421  0.15008195 -0.04772663  0.04474661 -0.0292393 ]\n",
      " [ 0.25713098  0.07987424  0.20038895  0.17371011 -0.15805443]\n",
      " [ 0.0833302  -0.23158753  0.06115128  0.22162879 -0.15033774]\n",
      " [ 0.05864166  0.00857524 -0.01121869  0.07024857  0.02779203]\n",
      " [-0.1440834   0.12450769  0.23628579 -0.05951619 -0.0177875 ]\n",
      " [-0.05881212  0.16882858  0.02784654  0.2273872   0.2029683 ]\n",
      " [-0.02392894 -0.12567039  0.13505512  0.00495115  0.02218841]\n",
      " [-0.03621229  0.00953717  0.02918455 -0.15046723 -0.00459008]\n",
      " [ 0.02230585  0.16420995 -0.09683681 -0.12207036 -0.09930956]\n",
      " [-0.17144859  0.10410456 -0.14240402 -0.16437408 -0.00486595]\n",
      " [-0.22193624  0.22296131  0.26744887  0.05135829 -0.01306308]\n",
      " [-0.17061386  0.02216626 -0.04120101  0.2100499   0.03463897]\n",
      " [-0.24193631 -0.05702585  0.05576601  0.04026042  0.12665117]\n",
      " [-0.18723188 -0.00200439  0.04618283 -0.20389202 -0.12695318]\n",
      " [ 0.14414386  0.01322108  0.00805242  0.0127957   0.02368974]\n",
      " [-0.11178961  0.02023529 -0.03484927 -0.00266254 -0.04548309]\n",
      " [-0.01015372  0.09343906  0.02568094  0.00283795  0.10685838]\n",
      " [-0.07206235  0.03273929 -0.19539379  0.19001405 -0.01019899]\n",
      " [-0.05847965  0.22637661 -0.09595555  0.04512106 -0.12562092]\n",
      " [ 0.0033985  -0.12772705  0.01271854 -0.19988924  0.0648166 ]\n",
      " [-0.19097686  0.00963495 -0.09087744  0.0357212   0.11758102]\n",
      " [ 0.0518623  -0.06989427 -0.04540985 -0.17683068 -0.12098341]\n",
      " [ 0.01051888 -0.24501777 -0.0032214  -0.17710966 -0.0045655 ]\n",
      " [-0.10563684  0.16781829 -0.11045138 -0.05933339 -0.09602148]\n",
      " [ 0.02687704  0.20063341 -0.01028419 -0.06251082  0.14586511]\n",
      " [-0.00371892 -0.12813763 -0.01797139 -0.01585456 -0.07382307]\n",
      " [ 0.06974337 -0.23326676  0.28104305 -0.08837765 -0.17487937]\n",
      " [-0.09945977 -0.03048247  0.19355102  0.17909364  0.15162355]\n",
      " [ 0.02060763  0.00978476 -0.04379413  0.10805457 -0.18886223]\n",
      " [-0.04675217  0.19547462 -0.02813261  0.02584765  0.13456982]\n",
      " [-0.28297815 -0.22648923 -0.05720954  0.17241229 -0.1822769 ]\n",
      " [ 0.19390909  0.08856488  0.1363347  -0.15769795  0.0027146 ]\n",
      " [ 0.00100014  0.16046748 -0.21157254  0.27416241 -0.0708148 ]\n",
      " [ 0.03447911  0.03516446  0.09631854  0.0389281  -0.01104376]\n",
      " [ 0.06301394 -0.14117604  0.1938837  -0.01517727 -0.01442021]\n",
      " [ 0.02557272  0.12644731  0.01937552 -0.01823764  0.01576256]\n",
      " [-0.20254883  0.09101837 -0.05875047 -0.02205558  0.11411371]\n",
      " [-0.19804952  0.00151075 -0.18247119  0.19405709 -0.06544333]\n",
      " [-0.0946337  -0.03273205  0.10712455 -0.23069285  0.15971154]\n",
      " [-0.07786686 -0.16498788 -0.18151529 -0.13389298  0.08378389]\n",
      " [-0.19965117  0.14092128  0.02021465  0.16804992  0.14625706]\n",
      " [-0.01981178  0.06832211  0.19194467  0.01809014 -0.07013623]\n",
      " [-0.05150634  0.1116959   0.09583887 -0.27057466  0.09259003]\n",
      " [ 0.19792715 -0.16997404  0.12747689  0.08989324 -0.00554822]\n",
      " [-0.03912424 -0.08627584 -0.26181439 -0.04214298  0.19255123]\n",
      " [-0.00128828  0.27235797 -0.10628957  0.21058786  0.1916448 ]\n",
      " [ 0.05566701 -0.03213667 -0.01172276 -0.00064377  0.18671551]\n",
      " [ 0.16558437 -0.23615849 -0.2339783  -0.19808799 -0.22866204]\n",
      " [-0.08176888 -0.13619663 -0.02145891 -0.07688159  0.09779947]\n",
      " [ 0.11612629 -0.06143057 -0.03704789 -0.11856514  0.132101  ]\n",
      " [ 0.04875147 -0.08271083  0.03039573  0.00649122 -0.06280462]\n",
      " [ 0.10300893 -0.10591444  0.12780124  0.06731028 -0.07674357]\n",
      " [ 0.09467018 -0.08178324 -0.16792941  0.01833756 -0.1669337 ]\n",
      " [-0.15871753 -0.05731991 -0.06096692  0.08466049 -0.0569902 ]\n",
      " [-0.10702112  0.2156454  -0.10830659 -0.11653674  0.06618603]\n",
      " [ 0.15903465 -0.08637543 -0.09411678  0.09364071 -0.10648799]\n",
      " [-0.0123176  -0.08490725 -0.06462626 -0.06132169  0.10491804]\n",
      " [ 0.04921367  0.04802785  0.07442912  0.18711601 -0.09052597]\n",
      " [ 0.1673764   0.02304705  0.11258495 -0.23245916  0.07053856]\n",
      " [ 0.15929013 -0.10482813  0.01302148 -0.04338306 -0.10840179]\n",
      " [-0.05880287 -0.07845421 -0.19087467 -0.09451105 -0.07857301]\n",
      " [-0.06139769  0.25152805 -0.23304406  0.17956229 -0.06164945]\n",
      " [ 0.14624827 -0.11102019 -0.01719781  0.20423126 -0.10573556]\n",
      " [-0.06376138 -0.05340557 -0.08909706  0.08165838 -0.07277317]\n",
      " [ 0.07544384  0.22165078 -0.05841099 -0.0137001   0.20736508]\n",
      " [-0.05617075  0.16785786  0.15611391  0.19519658 -0.00968465]\n",
      " [-0.07427959  0.08007187  0.0780157  -0.03165667  0.10859991]\n",
      " [-0.20609093  0.09162175 -0.08670723  0.08092579 -0.15228033]\n",
      " [ 0.12016433  0.01996312  0.12125293 -0.01465791 -0.07496303]\n",
      " [-0.2331588  -0.06585256 -0.20380001  0.00251611  0.0706893 ]\n",
      " [ 0.07664743  0.20110707  0.18676728 -0.06643946 -0.08081567]\n",
      " [ 0.04043648 -0.16736549 -0.12699905 -0.06840378 -0.02182229]\n",
      " [-0.0623302   0.03066082 -0.08452205  0.1356163  -0.13171068]\n",
      " [-0.19425599  0.15642728  0.25588426 -0.07934509 -0.06094295]\n",
      " [-0.05720196 -0.11811805  0.21476577 -0.02357933  0.04289814]\n",
      " [ 0.22347368 -0.19585401 -0.15741478 -0.15967447  0.19030418]\n",
      " [-0.04996134  0.00479077  0.12213423  0.01248009 -0.05214535]\n",
      " [-0.07101883 -0.02482621 -0.20780158  0.12248319  0.07098501]\n",
      " [-0.08475541 -0.06105059 -0.00353028 -0.18648198 -0.0571126 ]\n",
      " [-0.12932086 -0.14943905 -0.02430626 -0.12478313  0.04624502]\n",
      " [ 0.00636466 -0.0398365   0.13025662 -0.07076886 -0.02555877]\n",
      " [-0.16050792  0.0292186   0.22412829  0.10445649 -0.17269231]\n",
      " [ 0.06025249  0.20924807  0.10730424 -0.09136206 -0.08071998]\n",
      " [ 0.00461865  0.01167639 -0.11109929  0.10641957 -0.05486466]\n",
      " [ 0.16793436  0.23509093 -0.05328845 -0.06933136 -0.01442909]]\n",
      "Softmax_Layer/bias:0 with value [ 0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    restore_saver = tf.train.import_meta_graph(\"./Models/yen/mnist_5.ckpt.meta\")\n",
    "    restore_saver.restore(sess, tf.train.latest_checkpoint('./Models/yen/'))\n",
    "#     sess.run(tf.global_variables_initializer()) # initialize the weights \n",
    "#     sess.run(tf.local_variables_initializer()) # initialize the local variables hidden in the tf.metrics.recallmethod.\n",
    "\n",
    "    all_vars = tf.trainable_variables()\n",
    "    for v in all_vars:\n",
    "\n",
    "        print(\"%s with value %s\" % (v.name, sess.run(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Models/yen/mnist_5.ckpt\n",
      "[<tf.Variable 'Softmax_Layer/kernel:0' shape=(128, 5) dtype=float32_ref>, <tf.Variable 'Softmax_Layer/bias:0' shape=(5,) dtype=float32_ref>]\n",
      "   1 epochs, Validation loss:1.63157, Best loss:0.00000, Accuracy:0.08000/ 0.23802\n",
      "   2 epochs, Validation loss:1.62380, Best loss:0.00000, Accuracy:0.10667/ 0.25797\n",
      "   3 epochs, Validation loss:1.61584, Best loss:0.00000, Accuracy:0.13333/ 0.27669\n",
      "   4 epochs, Validation loss:1.60770, Best loss:0.00000, Accuracy:0.18000/ 0.29850\n",
      "   5 epochs, Validation loss:1.59941, Best loss:0.00000, Accuracy:0.23333/ 0.32010\n",
      "   6 epochs, Validation loss:1.59098, Best loss:0.00000, Accuracy:0.25333/ 0.33944\n",
      "   7 epochs, Validation loss:1.58245, Best loss:0.00000, Accuracy:0.29333/ 0.35569\n",
      "   8 epochs, Validation loss:1.57384, Best loss:0.00000, Accuracy:0.35333/ 0.37564\n",
      "   9 epochs, Validation loss:1.56519, Best loss:0.00000, Accuracy:0.38000/ 0.39066\n",
      "  10 epochs, Validation loss:1.55651, Best loss:0.00000, Accuracy:0.38667/ 0.40547\n",
      "  11 epochs, Validation loss:1.54783, Best loss:0.00000, Accuracy:0.38000/ 0.41823\n",
      "  12 epochs, Validation loss:1.53916, Best loss:0.00000, Accuracy:0.38000/ 0.42934\n",
      "  13 epochs, Validation loss:1.53052, Best loss:0.00000, Accuracy:0.40000/ 0.44086\n",
      "  14 epochs, Validation loss:1.52191, Best loss:0.00000, Accuracy:0.41333/ 0.44826\n",
      "  15 epochs, Validation loss:1.51336, Best loss:0.00000, Accuracy:0.42667/ 0.46040\n",
      "  16 epochs, Validation loss:1.50486, Best loss:0.00000, Accuracy:0.44000/ 0.47377\n",
      "  17 epochs, Validation loss:1.49642, Best loss:0.00000, Accuracy:0.46000/ 0.48550\n",
      "  18 epochs, Validation loss:1.48803, Best loss:0.00000, Accuracy:0.46667/ 0.49702\n",
      "  19 epochs, Validation loss:1.47969, Best loss:0.00000, Accuracy:0.49333/ 0.50689\n",
      "  20 epochs, Validation loss:1.47139, Best loss:0.00000, Accuracy:0.52000/ 0.52067\n",
      "  21 epochs, Validation loss:1.46312, Best loss:0.00000, Accuracy:0.53333/ 0.53466\n",
      "  22 epochs, Validation loss:1.45487, Best loss:0.00000, Accuracy:0.54667/ 0.54577\n",
      "  23 epochs, Validation loss:1.44664, Best loss:0.00000, Accuracy:0.54000/ 0.55791\n",
      "  24 epochs, Validation loss:1.43841, Best loss:0.00000, Accuracy:0.57333/ 0.56964\n",
      "  25 epochs, Validation loss:1.43020, Best loss:0.00000, Accuracy:0.58667/ 0.58136\n",
      "  26 epochs, Validation loss:1.42200, Best loss:0.00000, Accuracy:0.59333/ 0.59371\n",
      "  27 epochs, Validation loss:1.41383, Best loss:0.00000, Accuracy:0.60000/ 0.60625\n",
      "  28 epochs, Validation loss:1.40573, Best loss:0.00000, Accuracy:0.60667/ 0.61860\n",
      "  29 epochs, Validation loss:1.39773, Best loss:0.00000, Accuracy:0.61333/ 0.62847\n",
      "  30 epochs, Validation loss:1.38988, Best loss:0.00000, Accuracy:0.62000/ 0.63752\n",
      "  31 epochs, Validation loss:1.38222, Best loss:0.00000, Accuracy:0.63333/ 0.64637\n",
      "  32 epochs, Validation loss:1.37481, Best loss:0.00000, Accuracy:0.63333/ 0.65542\n",
      "  33 epochs, Validation loss:1.36768, Best loss:0.00000, Accuracy:0.64000/ 0.66283\n",
      "  34 epochs, Validation loss:1.36087, Best loss:0.00000, Accuracy:0.65333/ 0.67064\n",
      "  35 epochs, Validation loss:1.35440, Best loss:0.00000, Accuracy:0.66000/ 0.67661\n",
      "  36 epochs, Validation loss:1.34826, Best loss:0.00000, Accuracy:0.68000/ 0.68114\n",
      "  37 epochs, Validation loss:1.34244, Best loss:0.00000, Accuracy:0.69333/ 0.68628\n",
      "  38 epochs, Validation loss:1.33691, Best loss:0.00000, Accuracy:0.69333/ 0.69019\n",
      "  39 epochs, Validation loss:1.33164, Best loss:0.00000, Accuracy:0.70667/ 0.69574\n",
      "  40 epochs, Validation loss:1.32659, Best loss:0.00000, Accuracy:0.70667/ 0.69965\n",
      "  41 epochs, Validation loss:1.32172, Best loss:0.00000, Accuracy:0.70667/ 0.70397\n",
      "  42 epochs, Validation loss:1.31701, Best loss:0.00000, Accuracy:0.71333/ 0.70870\n",
      "  43 epochs, Validation loss:1.31244, Best loss:0.00000, Accuracy:0.70667/ 0.71282\n",
      "  44 epochs, Validation loss:1.30797, Best loss:0.00000, Accuracy:0.70667/ 0.71672\n",
      "  45 epochs, Validation loss:1.30361, Best loss:0.00000, Accuracy:0.70667/ 0.71899\n",
      "  46 epochs, Validation loss:1.29934, Best loss:0.00000, Accuracy:0.71333/ 0.72084\n",
      "  47 epochs, Validation loss:1.29517, Best loss:0.00000, Accuracy:0.72000/ 0.72434\n",
      "  48 epochs, Validation loss:1.29110, Best loss:0.00000, Accuracy:0.72667/ 0.72701\n",
      "  49 epochs, Validation loss:1.28714, Best loss:0.00000, Accuracy:0.72667/ 0.72948\n",
      "  50 epochs, Validation loss:1.28328, Best loss:0.00000, Accuracy:0.72667/ 0.73071\n",
      "  51 epochs, Validation loss:1.27954, Best loss:0.00000, Accuracy:0.73333/ 0.73401\n",
      "  52 epochs, Validation loss:1.27591, Best loss:0.00000, Accuracy:0.73333/ 0.73442\n",
      "  53 epochs, Validation loss:1.27241, Best loss:0.00000, Accuracy:0.74000/ 0.73771\n",
      "  54 epochs, Validation loss:1.26902, Best loss:0.00000, Accuracy:0.74667/ 0.73853\n",
      "  55 epochs, Validation loss:1.26575, Best loss:0.00000, Accuracy:0.75333/ 0.74141\n",
      "  56 epochs, Validation loss:1.26261, Best loss:0.00000, Accuracy:0.75333/ 0.74182\n",
      "  57 epochs, Validation loss:1.25958, Best loss:0.00000, Accuracy:0.75333/ 0.74347\n",
      "  58 epochs, Validation loss:1.25666, Best loss:0.00000, Accuracy:0.75333/ 0.74491\n",
      "  59 epochs, Validation loss:1.25386, Best loss:0.00000, Accuracy:0.75333/ 0.74655\n",
      "  60 epochs, Validation loss:1.25115, Best loss:0.00000, Accuracy:0.76000/ 0.74697\n",
      "  61 epochs, Validation loss:1.24855, Best loss:0.00000, Accuracy:0.76000/ 0.74841\n",
      "  62 epochs, Validation loss:1.24604, Best loss:0.00000, Accuracy:0.75333/ 0.74943\n",
      "  63 epochs, Validation loss:1.24362, Best loss:0.00000, Accuracy:0.75333/ 0.75087\n",
      "  64 epochs, Validation loss:1.24128, Best loss:0.00000, Accuracy:0.76000/ 0.75129\n",
      "  65 epochs, Validation loss:1.23902, Best loss:0.00000, Accuracy:0.76000/ 0.75355\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "no_update_tolerant = 20\n",
    "\n",
    "no_update_progress = 0\n",
    "current_best_accuracy = 0.0\n",
    "current_best_loss = 0.0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    restore_saver = tf.train.import_meta_graph(\"./Models/yen/mnist_5.ckpt.meta\") # load meta graph\n",
    "    restore_saver.restore(sess, tf.train.latest_checkpoint('./Models/yen/')) # restore weights\n",
    "#     sess.run(tf.global_variables_initializer()) # initialize the weights \n",
    "#     sess.run(tf.local_variables_initializer()) # initialize the local variables hidden in the tf.metrics.recallmethod.\n",
    "\n",
    "    \"\"\"\n",
    "    Graph Define Step\n",
    "    \n",
    "    1. Restore the variable about the component in graph which help to retrieve and assign value\n",
    "    \"\"\"\n",
    "    graph = tf.get_default_graph() # get original graph\n",
    "    X = graph.get_tensor_by_name(\"Input_X:0\") # assign placeholder variables with input X\n",
    "    y = graph.get_tensor_by_name(\"Input_Label:0\")# assign placeholder variables with input Label\n",
    "#     mode = graph.get_tensor_by_name(\"Mode:0\")# assign placeholder variables with input Mode\n",
    "    loss = graph.get_tensor_by_name(\"Loss:0\") # assign variables about loss\n",
    "    Y_proba = graph.get_tensor_by_name(\"Softmax_Layer/Softmax:0\") # assign variables about loss\n",
    "    accuracy = graph.get_tensor_by_name(\"Accuracy:0\") # assign variables  about accuracy\n",
    "#     optimizer = graph.get_operation_by_name(\"Adam\")# assign variables about optimizer which is adam optimizer\n",
    "#     print(type(optimizer))\n",
    "#     print(Y_proba.op.inputs[0])\n",
    "    \"\"\"\n",
    "    2. Get the softmax layer which is what we would like to train\n",
    "    \"\"\"\n",
    "    output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"Softmax_Layer\") # get softmax layer by scope name\n",
    "    print(output_layer_vars)\n",
    "    \n",
    "    \"\"\"\n",
    "    3. Define the optimizer and assign to only update on softmax_layer which defined above\n",
    "    \"\"\"\n",
    "    optimizer = tf.train.AdamOptimizer(0.0017, name=\"Op\")\n",
    "    training_op = optimizer.minimize(loss, var_list=output_layer_vars) # minimize the loss and only update certern variables\n",
    "    tf.variables_initializer([optimizer.get_slot(var, name) for name in optimizer.get_slot_names() for var in output_layer_vars])\n",
    "    tf.variables_initializer(list(optimizer._get_beta_accumulators()))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \"\"\"\n",
    "    Training Step\n",
    "    \"\"\"\n",
    "    for epochs in range(1000): # training on 1000 epochs\n",
    "        _, train_loss = sess.run([training_op, loss], feed_dict={X:X_train2, y:y_train2}) # feed with training variables\n",
    "        valid_loss, valid_accuracy = sess.run([loss, accuracy], feed_dict={X:X_valid2, y:y_valid2}) # feed with validation variables\n",
    "        test_loss ,  test_accuracy = sess.run([loss, accuracy], feed_dict={X:X_test2, y:y_test2}) # feed with testing variables\n",
    "        \n",
    "        print(\"{:4d} epochs, Validation loss:{:.5f}, Best loss:{:.5f}, Accuracy:{:.5f}/ {:.5f}\".format(\n",
    "            epochs+1,\n",
    "            valid_loss,\n",
    "            current_best_loss,                                                                                       \n",
    "            valid_accuracy,\n",
    "            test_accuracy\n",
    "        ))\n",
    "        \n",
    "        if valid_accuracy > current_best_accuracy: # if better\n",
    "            current_best_accuracy = valid_accuracy # keep record\n",
    "        else:                                      # if not better\n",
    "            no_update_progress += 1                # record on no update\n",
    "\n",
    "        if valid_loss < current_best_loss: # if better\n",
    "            current_best_loss = valid_loss # keep record            \n",
    "            \n",
    "        if no_update_progress == no_update_tolerant: break # stop training\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
